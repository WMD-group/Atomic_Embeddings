{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to ElementEmbeddings","text":"<p>This site contains the project documentation for the <code>ElementEmbeddings</code> package which provides tools and examples of analysing and visualising elemental representation data.</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<p>The documentation consists of the following six parts:</p> <ol> <li>About</li> <li>Getting Started</li> <li>Python API</li> <li>Tutorials</li> <li>Reference</li> <li>Contributing</li> </ol>"},{"location":"#project-overview","title":"Project Overview","text":"<p>Analyse elemental representation data.</p> <p>Modules exported by this package:</p> <ul> <li><code>elementembeddings.core</code>: Provides the <code>Embedding</code> class.</li> <li><code>elementembeddings.composition</code>: Tools to featurise compositions.</li> <li><code>elementembeddings.plotter</code>: Tools to plot embeddings.</li> </ul>"},{"location":"about/","title":"About the ElementEmbeddings package","text":"<p>====</p> <p> </p> <p>The Element Embeddings package provides high-level tools for analysing elemental embeddings data. This primarily involves visualising the correlation between embedding schemes using different statistical measures.</p> <ul> <li>Documentation: https://wmd-group.github.io/ElementEmbeddings/</li> <li>Examples: https://github.com/WMD-group/ElementEmbeddings/tree/main/examples</li> </ul>"},{"location":"about/#motivation","title":"Motivation","text":"<p>Machine learning approaches for materials informatics have become increasingly widespread. Some of these involve the use of deep learning techniques where the representation of the elements is learned rather than specified by the user of the model. While an important goal of machine learning training is to minimise the chosen error function to make more accurate predictions, it is also important for us material scientists to be able to interpret these models. As such, we aim to evaluate and compare different atomic embedding schemes in a consistent framework.</p>"},{"location":"contribution/","title":"Contributing","text":"<p>This is a quick guide on how to follow best practice and contribute smoothly to <code>ElementEmbeddings</code>.</p>"},{"location":"contribution/#code-contributions","title":"Code contributions","text":"<p>We are always looking for ways to make <code>ElementEmbeddings</code> better and a more useful to a wider community. For making contributions, use the \"Fork and Pull\" workflow to make contributions and stick as closely as possible to the following:</p> <ul> <li>Code style should comply with PEP8 where possible. Google's house style is also helpful, including a good model for docstrings.</li> <li>Please use comments liberally when adding nontrivial features, and take the chance to clean up other people's code while looking at it.</li> <li>Add tests wherever possible, and use the test suite to check if you broke anything.</li> </ul>"},{"location":"contribution/#workflow","title":"Workflow","text":"<p>We follow the [GitHub flow] (https://guides.github.com/introduction/flow/index.html), using branches for new work and pull requests for verifying the work.</p> <p>The steps for a new piece of work can be summarised as follows:</p> <ol> <li>Push up or create an issue.</li> <li>Create a branch from main, with a sensible name that relates to the issue.</li> <li>Do the work and commit changes to the branch. Push the branch    regularly to GitHub to make sure no work is accidentally lost.</li> <li>Write or update unit tests for the code you work on.</li> <li>When you are finished with the work, ensure that all of the unit    tests pass on your own machine.</li> <li>Open a pull request on the pull request page.</li> <li>If nobody acknowledges your pull request promptly, feel free to poke one of the main developers into action.</li> </ol>"},{"location":"contribution/#pull-requests","title":"Pull requests","text":"<p>For a general overview of using pull requests on GitHub look in the GitHub docs.</p> <p>When creating a pull request you should:</p> <ul> <li>Ensure that the title succinctly describes the changes so it is easy to read on the overview page</li> <li>Reference the issue which the pull request is closing</li> </ul> <p>Recommended reading: How to Write the Perfect Pull Request</p>"},{"location":"contribution/#dev-requirements","title":"Dev requirements","text":"<p>When developing locally, it is recommended to install the python packages in <code>requirements-dev.txt</code>.</p> <pre><code>pip install -r requirements-dev.txt\n</code></pre> <p>This will allow you to run the tests locally with pytest as described in the main README, as well as run pre-commit hooks to automatically format python files with isort and black. To install the pre-commit hooks (only needs to be done once):</p> <pre><code>pre-commit install\npre-commit run --all-files # optionally run hooks on all files\n</code></pre> <p>Pre-commit hooks will check all files when you commit changes, automatically fixing any files which are not formatted correctly. Those files will need to be staged again before re-attempting the commit.</p>"},{"location":"contribution/#bug-reports-feature-requests-and-questions","title":"Bug reports, feature requests and questions","text":"<p>Please use the Issue Tracker to report bugs or request features in the first instance. Contributions are always welcome. </p>"},{"location":"installation/","title":"Getting Started","text":"<p>The latest stable release can be installed via pip using:</p> <pre><code>pip install ElementEmbeddings\n</code></pre>"},{"location":"installation/#developers-installation-optional","title":"Developer's installation (optional)","text":"<p>For development work, <code>ElementEmbeddings</code> can eb installed from a copy of the source repository; this is preferred if using experimental code branches.</p> <p>To clone the project from Github and make a local installation:</p> <pre><code>git clone https://github.com/WMD-group/ElementEmbeddings.git\ncd ElementEmbeddings\npip install -e .\n</code></pre> <p>With <code>-e</code>, pip will create links to the source folder so that the changes to the code will be reflected on the PATH.</p>"},{"location":"reference/","title":"Elemental Embeddings","text":"<p>The data contained in this repository are a collection of various elemental representation/embedding schemes. We provide the literature source for these representations as well as the data source for which the files were obtained. A majority of these representations have been obtained from the following repositories:</p> <ul> <li>lrcfmd/ElMD</li> <li>Kaaiian/CBFV</li> </ul>"},{"location":"reference/#linear-representations","title":"Linear representations","text":"<p>For the linear/scalar representations, the <code>Embedding</code> class will load these representations as one-hot vectors where the vector components are ordered following the scale (i.e. the <code>atomic</code> representation is ordered by atomic numbers).</p>"},{"location":"reference/#modified-pettifor-scale","title":"Modified Pettifor scale","text":"<p>The following paper describes the details of the modified Pettifor chemical scale: The optimal one-dimensional periodic table: a modified Pettifor chemical scale from data mining</p> <p>Data source</p>"},{"location":"reference/#atomic-numbers","title":"Atomic numbers","text":"<p>We included <code>atomic</code> as a linear representation to generate one-hot vectors corresponding to the atomic numbers</p>"},{"location":"reference/#vector-representations","title":"Vector representations","text":"<p>The following representations are all vector representations (some are local, some are distributed) and the <code>Embedding</code> class will load these representations as they are.</p>"},{"location":"reference/#magpie","title":"Magpie","text":"<p>The following paper describes the details of the Materials Agnostic Platform for Informatics and Exploration (Magpie) framework: A general-purpose machine learning framework for predicting properties of inorganic materials</p> <p>The source code for Magpie can be found here</p> <p>Data source</p> <p>The 22 dimensional embedding vector includes the following elemental properties:</p> Click to see the 22 properties  * Number; * Mendeleev number; * Atomic weight; * Melting temperature; * Group number; * Period; * Covalent Radius;  * Electronegativity; * no. of s, p, d, f  valence electrons (4 features); * no. of valence electrons; * no. of unfilled: s, p, d, f orbitals (4 features), * no. of unfilled orbtials * GSvolume_pa (DFT volume per atom of T=0K ground state from the OQMD) * GSbandgap(DFT bandgap energy of T=0K ground state from the OQMD) * GSmagmom (DFT magnetic moment of T=0K ground state from the OQMD) * Space Group Number  <ul> <li><code>magpie_sc</code> is a scaled version of the magpie embeddings. Data source</li> </ul>"},{"location":"reference/#mat2vec","title":"mat2vec","text":"<p>The following paper describes the implementation of mat2vec: Unsupervised word embeddings capture latent knowledge from materials science literature</p> <p>Data source</p>"},{"location":"reference/#matscholar","title":"MatScholar","text":"<p>The following paper describes the natural language processing implementation of Materials Scholar (matscholar): Named Entity Recognition and Normalization Applied to Large-Scale Information Extraction from the Materials Science Literature</p> <p>Data source</p>"},{"location":"reference/#megnet","title":"MEGnet","text":"<p>The following paper describes the details of the construction of the MatErials Graph Network (MEGNet): Graph Networks as a Universal Machine Learning Framework for Molecules and Crystals</p> <p>Data source</p>"},{"location":"reference/#oliynyk","title":"Oliynyk","text":"<p>The following paper describes the details: High-Throughput Machine-Learning-Driven Synthesis of Full-Heusler Compounds</p> <p>Data source</p> <p>The 44 features of the embedding vector are formed of the following properties:</p>  Click to see the 44 features!  * Number * Atomic_Weight * Period * Group * Families * Metal * Nonmetal * Metalliod * Mendeleev_Number * l_quantum_number * Atomic_Radius * Miracle_Radius_[pm] * Covalent_Radius * Zunger_radii_sum * Ionic_radius * crystal_radius * Pauling_Electronegativity * MB_electonegativity * Gordy_electonegativity * Mulliken_EN * Allred-Rockow_electronegativity * Metallic_valence * Number_of_valence_electrons * Gilmor_number_of_valence_electron * valence_s * valence_p * valence_d * valence_f * Number_of_unfilled_s_valence_electrons * Number_of_unfilled_p_valence_electrons * Number_of_unfilled_d_valence_electrons * Number_of_unfilled_f_valence_electrons * Outer_shell_electrons * 1st_ionization_potential_(kJ/mol) * Polarizability(A^3) * Melting_point_(K) * Boiling_Point_(K) * Density_(g/mL) * Specific_heat_(J/g_K)_ * Heat_of_fusion_(kJ/mol)_ * Heat_of_vaporization_(kJ/mol)_ * Thermal_conductivity_(W/(m_K))_ * Heat_atomization(kJ/mol) * Cohesive_energy  <ul> <li><code>oliynyk_sc</code> is a scaled version of the oliynyk embeddings: Data source</li> </ul>"},{"location":"reference/#random","title":"Random","text":"<p>This is a set of 200-dimensional vectors in which the components are randomly generated</p> <p>The 118 200-dimensional vectors in <code>random_200_new</code> were generated using the following code:</p> <pre><code>import numpy as np\nmu , sigma = 0 , 1 # mean and standard deviation s = np.random.normal(mu, sigma, 1000)\ns = np.random.default_rng(seed=42).normal(mu, sigma, (118,200))\n</code></pre>"},{"location":"reference/#skipatom","title":"SkipAtom","text":"<p>The following paper describes the details: Distributed representations of atoms and materials for machine learning</p> <p>Data source</p>"},{"location":"tutorials/","title":"Tutorial","text":"<p>Here we will demonstrate how to use some of <code>ElementEmbeddings</code>'s features. For full worked examples of using the package, please refer to the Jupyter notebooks in the examples section of the Github repo.</p>"},{"location":"tutorials/#elementembeddings","title":"ElementEmbeddings","text":"<p>The <code>Embedding</code> class lies at the heart of the package. It handles elemental representation data and enables analysis and visualisation.</p> <p>For simple usage, you can instantiate an Embedding object using one of the embeddings in the data directory. For this example, let's use the magpie elemental representation.</p> <pre><code># Import the class\n&gt;&gt;&gt; from elementembeddings.core import Embedding\n# Load the magpie data\n&gt;&gt;&gt; magpie = Embedding.load_data('magpie')\n</code></pre> <p>We can access some of the properties of the <code>Embedding</code> class. For example, we can find the dimensions of the elemental representation and the list of elements for which an embedding exists.</p> <pre><code># Print out some of the properties of the ElementEmbeddings class\n&gt;&gt;&gt; print(f'The magpie representation has embeddings of dimension {magpie.dim}') \n&gt;&gt;&gt; print(f'The magpie representation contains these elements: \\n {magpie.element_list}') # prints out all the elements considered for this representation\n&gt;&gt;&gt; print(f'The magpie representation contains these features: \\n {magpie.feature_labels}') # Prints out the feature labels of the chosen representation\nThe magpie representation has embeddings of dimension 22\nThe magpie representation contains these elements:\n['H', 'He', 'Li', 'Be', 'B', 'C', 'N', 'O', 'F', 'Ne', 'Na', 'Mg', 'Al', 'Si', 'P', 'S', 'Cl', 'Ar', 'K', 'Ca', 'Sc', 'Ti', 'V', 'Cr', 'Mn', 'Fe', 'Co', 'Ni', 'Cu', 'Zn', 'Ga', 'Ge', 'As', 'Se', 'Br', 'Kr', 'Rb', 'Sr', 'Y', 'Zr', 'Nb', 'Mo', 'Tc', 'Ru', 'Rh', 'Pd', 'Ag', 'Cd', 'In', 'Sn', 'Sb', 'Te', 'I', 'Xe', 'Cs', 'Ba', 'La', 'Ce', 'Pr', 'Nd', 'Pm', 'Sm', 'Eu', 'Gd', 'Tb', 'Dy', 'Ho', 'Er', 'Tm', 'Yb', 'Lu', 'Hf', 'Ta', 'W', 'Re', 'Os', 'Ir', 'Pt', 'Au', 'Hg', 'Tl', 'Pb', 'Bi', 'Po', 'At', 'Rn', 'Fr', 'Ra', 'Ac', 'Th', 'Pa', 'U', 'Np', 'Pu', 'Am', 'Cm', 'Bk']\nThe magpie representation contains these features:\n['Number', 'MendeleevNumber', 'AtomicWeight', 'MeltingT', 'Column', 'Row', 'CovalentRadius', 'Electronegativity', 'NsValence', 'NpValence', 'NdValence', 'NfValence', 'NValence', 'NsUnfilled', 'NpUnfilled', 'NdUnfilled', 'NfUnfilled', 'NUnfilled', 'GSvolume_pa', 'GSbandgap', 'GSmagmom', 'SpaceGroupNumber']\n</code></pre>"},{"location":"tutorials/#plotting","title":"Plotting","text":"<p>We can quickly generate heatmaps of distance/similarity measures between the element vectors using <code>heatmap_plotter</code> and plot the representations in two dimensions using the <code>dimension_plotter</code> from the plotter module. Before we do that, we will standardise the embedding using the <code>standardise</code> method available to the Embedding class</p> <pre><code>from elementembeddings.plotter import heatmap_plotter, dimension_plotter\nimport matplotlib.pyplot as plt\nmagpie.standardise(inplace=True) # Standardises the representation\nfig, ax = plt.subplots(1, 1, figsize=(6,6))\nheatmap_params = {\"vmin\": -1, \"vmax\": 1}\nheatmap_plotter(embedding=magpie, metric=\"cosine_similarity\",show_axislabels=False,cmap=\"Blues_r\",ax=ax, **heatmap_params)\nax.set_title(\"Magpie cosine similarities\")\nfig.tight_layout()\nfig.show()\n</code></pre> <p></p> <pre><code>fig, ax = plt.subplots(1, 1, figsize=(6,6))\nreducer_params={\"n_neighbors\": 30, \"random_state\":42}\nscatter_params = {\"s\":100}\ndimension_plotter(embedding=magpie, reducer=\"umap\",n_components=2,ax=ax,adjusttext=True,reducer_params=reducer_params, scatter_params=scatter_params)\nax.set_title(\"Magpie UMAP (n_neighbours=30)\")\nax.legend().remove()\nhandles, labels = ax1.get_legend_handles_labels()\nfig.legend(handles, labels, bbox_to_anchor=(1.25, 0.5), loc=\"center right\", ncol=1)\nfig.tight_layout()\nfig.show()\n</code></pre> <p></p>"},{"location":"tutorials/#compositions","title":"Compositions","text":"<p>The package can also be used to featurise compositions. Your data could be a list of formula strings or a pandas dataframe of the following format:</p> formula CsPbI3 Fe2O3 NaCl ZnS <p>The <code>composition_featuriser</code> function can be used to featurise the data. The compositions can be featurised using different representation schemes and different types of pooling through the <code>embedding</code> and <code>stats</code> arguments respectively.</p> <pre><code>from elementembeddings.composition import composition_featuriser\ndf_featurised = composition_featuriser(df, embedding=\"magpie\", stats=[\"mean\",\"sum\"])\ndf_featurised\n</code></pre> formula mean_Number mean_MendeleevNumber mean_AtomicWeight mean_MeltingT mean_Column mean_Row mean_CovalentRadius mean_Electronegativity mean_NsValence mean_NpValence mean_NdValence mean_NfValence mean_NValence mean_NsUnfilled mean_NpUnfilled mean_NdUnfilled mean_NfUnfilled mean_NUnfilled mean_GSvolume_pa mean_GSbandgap mean_GSmagmom mean_SpaceGroupNumber sum_Number sum_MendeleevNumber sum_AtomicWeight sum_MeltingT sum_Column sum_Row sum_CovalentRadius sum_Electronegativity sum_NsValence sum_NpValence sum_NdValence sum_NfValence sum_NValence sum_NsUnfilled sum_NpUnfilled sum_NdUnfilled sum_NfUnfilled sum_NUnfilled sum_GSvolume_pa sum_GSbandgap sum_GSmagmom sum_SpaceGroupNumber CsPbI3 59.2 74.8 144.16377238 412.55 13.2 5.4 161.39999999999998 2.22 1.8 3.4 8.0 2.8000000000000003 16.0 0.2 1.4 0.0 0.0 1.6 54.584 0.6372 0.0 129.20000000000002 296.0 374.0 720.8188619 2062.75 66.0 27.0 807.0 11.100000000000001 9.0 17.0 40.0 14.0 80.0 1.0 7.0 0.0 0.0 8.0 272.92 3.186 0.0 646.0 Fe2O3 15.2 74.19999999999999 31.937640000000002 757.2800000000001 12.8 2.8 92.4 2.7960000000000003 2.0 2.4 2.4000000000000004 0.0 6.8 0.0 1.2 1.6 0.0 2.8 9.755 0.0 0.8442651200000001 98.80000000000001 76.0 371.0 159.6882 3786.4 64.0 14.0 462.0 13.98 10.0 12.0 12.0 0.0 34.0 0.0 6.0 8.0 0.0 14.0 48.775000000000006 0.0 4.2213256 494.0 NaCl 14.0 48.0 29.221384640000004 271.235 9.0 3.0 134.0 2.045 1.5 2.5 0.0 0.0 4.0 0.5 0.5 0.0 0.0 1.0 26.87041666665 1.2465 0.0 146.5 28.0 96.0 58.44276928000001 542.47 18.0 6.0 268.0 4.09 3.0 5.0 0.0 0.0 8.0 1.0 1.0 0.0 0.0 2.0 53.7408333333 2.493 0.0 293.0 ZnS 23.0 78.5 48.7225 540.52 14.0 3.5 113.5 2.115 2.0 2.0 5.0 0.0 9.0 0.0 1.0 0.0 0.0 1.0 19.8734375 1.101 0.0 132.0 46.0 157.0 97.445 1081.04 28.0 7.0 227.0 4.23 4.0 4.0 10.0 0.0 18.0 0.0 2.0 0.0 0.0 2.0 39.746875 2.202 0.0 264.0 <p>The returned dataframe contains the mean- and sum-pooled features of the magpie representation for the four formulas.</p>"},{"location":"python_api/composition/","title":"Composition module","text":"<p>This module provides a class for handling compositional embeddings.</p> Typical usage example <p>Fe2O3_magpie = CompositionalEmbedding(\"Fe2O3\", \"magpie\")</p>"},{"location":"python_api/composition/#elementembeddings.composition.CompositionalEmbedding","title":"<code>CompositionalEmbedding</code>","text":"<p>Class to handle compositional embeddings.</p> <p>Parameters:</p> Name Type Description Default <code>formula</code> <code>str</code> <p>A string formula e.g. CsPbI3, Li7La3Zr2O12</p> required <code>embedding</code> <code>Union[str, Embedding]</code> <p>Either a string name of the embedding</p> required <code>x</code> <code>int</code> <p>The non-stoichiometric amount.</p> <code>1</code> Source code in <code>src/elementembeddings/composition.py</code> <pre><code>class CompositionalEmbedding:\n\"\"\"\n    Class to handle compositional embeddings.\n    Args:\n        formula (str): A string formula e.g. CsPbI3, Li7La3Zr2O12\n        embedding (Union[str, Embedding]): Either a string name of the embedding\n        or an Embedding instance\n        x (int, optional): The non-stoichiometric amount.\n    \"\"\"\ndef __init__(self, formula: str, embedding: Union[str, Embedding], x=1):\n\"\"\"Initialise a CompositionalEmbedding instance.\"\"\"\nself.embedding = embedding\n# If a string has been passed for embedding, create an Embedding instance\nif isinstance(embedding, str):\nself.embedding = Embedding.load_data(embedding)\nself.embedding_name: str = self.embedding.embedding_name\n# Set an attribute for the formula\nself.formula = formula\n# Set an attribute for the comp dict\ncomp_dict = formula_parser(self.formula)\nself._natoms = 0\nfor el, v in comp_dict.items():\nif v &lt; 0:\nraise ValueError(\"Formula cannot contain negative amounts of elements\")\nself._natoms += abs(v)\nself.composition = comp_dict\n# Set an attribute for the element list\nself.element_list = list(self.composition.keys())\n# Set an attribute for the element matrix\nself.el_matrix = np.zeros(\nshape=(len(self.composition), len(self.embedding.embeddings[\"H\"]))\n)\nfor i, k in enumerate(self.composition.keys()):\nself.el_matrix[i] = self.embedding.embeddings[k]\nself.el_matrix = np.nan_to_num(self.el_matrix)\n# Set an attribute for the stoichiometric vector\nself.stoich_vector = np.array(list(self.composition.values()))\n# Set an attribute for the normalised stoichiometric vector\nself.norm_stoich_vector = self.stoich_vector / self._natoms\n@property\ndef fractional_composition(self):\n\"\"\"Fractional composition of the Composition.\"\"\"\nreturn _get_fractional_composition(self.formula)\n@property\ndef num_atoms(self) -&gt; float:\n\"\"\"Total number of atoms in Composition.\"\"\"\nreturn self._natoms\n@property\ndef embedding_dim(self) -&gt; int:\n\"\"\"Dimension of the embedding.\"\"\"\nreturn self.embedding.dim\ndef as_dict(self) -&gt; dict:\n# TO-DO: Need to create a dict representation for the embedding class\n\"\"\"Return the CompositionalEmbedding class as a dict.\"\"\"\nreturn {\n\"formula\": self.formula,\n\"composition\": self.composition,\n\"fractional_composition\": self.fractional_composition,\n# 'embedding':self.embedding.as_\n}\n# Se\n# Set an attribute\npass\ndef _mean_feature_vector(self) -&gt; np.ndarray:\n\"\"\"\n        Compute a weighted mean feature vector based of the embedding.\n        The dimension of the feature vector is the same as the embedding.\n        \"\"\"\nreturn np.dot(self.norm_stoich_vector, self.el_matrix)\ndef _variance_feature_vector(self) -&gt; np.ndarray:\n\"\"\"Compute a weighted variance feature vector.\"\"\"\ndiff_matrix = self.el_matrix - self._mean_feature_vector()\ndiff_matrix = diff_matrix**2\nreturn np.dot(self.norm_stoich_vector, diff_matrix)\ndef _minpool_feature_vector(self) -&gt; np.ndarray:\n\"\"\"Compute a min pooled feature vector.\"\"\"\nreturn np.min(self.el_matrix, axis=0)\ndef _maxpool_feature_vector(self) -&gt; np.ndarray:\n\"\"\"Compute a max pooled feature vector.\"\"\"\nreturn np.max(self.el_matrix, axis=0)\ndef _range_feature_vector(self) -&gt; np.ndarray:\n\"\"\"Compute a range feature vector.\"\"\"\nreturn np.ptp(self.el_matrix, axis=0)\ndef _sum_feature_vector(self) -&gt; np.ndarray:\n\"\"\"Compute the weighted sum feature vector.\"\"\"\nreturn np.dot(self.stoich_vector, self.el_matrix)\ndef _geometric_mean_feature_vector(self) -&gt; np.ndarray:\n\"\"\"Compute the geometric mean feature vector.\"\"\"\nreturn np.exp(np.dot(self.norm_stoich_vector, np.log(self.el_matrix)))\ndef _harmonic_mean_feature_vector(self) -&gt; np.ndarray:\n\"\"\"Compute the harmonic mean feature vector.\"\"\"\nreturn np.reciprocal(\nnp.dot(self.norm_stoich_vector, np.reciprocal(self.el_matrix))\n)\n_stats_functions_dict = {\n\"mean\": \"_mean_feature_vector\",\n\"variance\": \"_variance_feature_vector\",\n\"minpool\": \"_minpool_feature_vector\",\n\"maxpool\": \"_maxpool_feature_vector\",\n\"range\": \"_range_feature_vector\",\n\"sum\": \"_sum_feature_vector\",\n\"geometric_mean\": \"_geometric_mean_feature_vector\",\n\"harmonic_mean\": \"_harmonic_mean_feature_vector\",\n}\ndef feature_vector(self, stats: Union[str, list] = \"mean\"):\n\"\"\"\n        Compute a feature vector.\n        The feature vector is a concatenation of\n        the statistics specified in the stats argument.\n        Args:\n            stats (list): A list of strings specifying the statistics to be computed.\n            The default is ['mean'].\n        Returns:\n            np.ndarray: A feature vector of dimension (len(stats) * embedding_dim).\n        \"\"\"\nimplemented_stats = [\n\"mean\",\n\"variance\",\n\"minpool\",\n\"maxpool\",\n\"range\",\n\"sum\",\n\"geometric_mean\",\n\"harmonic_mean\",\n]\nif isinstance(stats, str):\nstats = [stats]\nif not isinstance(stats, list):\nraise ValueError(\"Stats argument must be a list of strings\")\nif not all([isinstance(s, str) for s in stats]):\nraise ValueError(\"Stats argument must be a list of strings\")\nif not all([s in implemented_stats for s in stats]):\nraise ValueError(\nf\" {[stat for stat in stats if stat not in implemented_stats]} \"\n\"are not valid statistics.\"\n)\nfeature_vector = []\nfor s in stats:\nfeature_vector.append(getattr(self, self._stats_functions_dict[s])())\nreturn np.concatenate(feature_vector)\ndef distance(\nself,\ncomp_other,\ndistance_metric: str = \"euclidean\",\nstats: Union[str, List[str]] = \"mean\",\n):\n\"\"\"\n        Compute the distance between two compositions.\n        Args:\n            comp_other (Union[str, CompositionalEmbedding]): The other composition.\n            distance_metric (str): The metric to be used. The default is 'euclidean'.\n        Returns:\n            float: The distance between the two CompositionalEmbedding objects.\n        \"\"\"\nif isinstance(comp_other, str):\ncomp_other = CompositionalEmbedding(comp_other, self.embedding)\nif not isinstance(comp_other, CompositionalEmbedding):\nraise ValueError(\n\"comp_other must be a string or a CompositionalEmbedding object.\"\n)\nif self.embedding_name != comp_other.embedding_name:\nraise ValueError(\n\"The two CompositionalEmbedding objects must have the same embedding.\"\n)\nreturn _composition_distance(\nself, comp_other, self.embedding, distance_metric, stats\n)\ndef __repr__(self):\nreturn (\nf\"CompositionalEmbedding(formula={self.formula}, \"\nf\"embedding={self.embedding_name})\"\n)\ndef __str__(self):\nreturn (\nf\"CompositionalEmbedding(formula={self.formula}, \"\nf\"embedding={self.embedding_name})\"\n)\ndef __eq__(self, other):\nif isinstance(other, self.__class__):\nreturn (\nself.formula == other.formula\nand self.embedding_name == other.embedding_name\n)\nelse:\nreturn False\ndef __ne__(self, other):\nreturn not self.__eq__(other)\ndef __hash__(self):\nreturn hash((self.formula, self.embedding))\n</code></pre>"},{"location":"python_api/composition/#elementembeddings.composition.CompositionalEmbedding.embedding_dim","title":"<code>embedding_dim: int</code>  <code>property</code>","text":"<p>Dimension of the embedding.</p>"},{"location":"python_api/composition/#elementembeddings.composition.CompositionalEmbedding.fractional_composition","title":"<code>fractional_composition</code>  <code>property</code>","text":"<p>Fractional composition of the Composition.</p>"},{"location":"python_api/composition/#elementembeddings.composition.CompositionalEmbedding.num_atoms","title":"<code>num_atoms: float</code>  <code>property</code>","text":"<p>Total number of atoms in Composition.</p>"},{"location":"python_api/composition/#elementembeddings.composition.CompositionalEmbedding.__init__","title":"<code>__init__(formula, embedding, x=1)</code>","text":"<p>Initialise a CompositionalEmbedding instance.</p> Source code in <code>src/elementembeddings/composition.py</code> <pre><code>def __init__(self, formula: str, embedding: Union[str, Embedding], x=1):\n\"\"\"Initialise a CompositionalEmbedding instance.\"\"\"\nself.embedding = embedding\n# If a string has been passed for embedding, create an Embedding instance\nif isinstance(embedding, str):\nself.embedding = Embedding.load_data(embedding)\nself.embedding_name: str = self.embedding.embedding_name\n# Set an attribute for the formula\nself.formula = formula\n# Set an attribute for the comp dict\ncomp_dict = formula_parser(self.formula)\nself._natoms = 0\nfor el, v in comp_dict.items():\nif v &lt; 0:\nraise ValueError(\"Formula cannot contain negative amounts of elements\")\nself._natoms += abs(v)\nself.composition = comp_dict\n# Set an attribute for the element list\nself.element_list = list(self.composition.keys())\n# Set an attribute for the element matrix\nself.el_matrix = np.zeros(\nshape=(len(self.composition), len(self.embedding.embeddings[\"H\"]))\n)\nfor i, k in enumerate(self.composition.keys()):\nself.el_matrix[i] = self.embedding.embeddings[k]\nself.el_matrix = np.nan_to_num(self.el_matrix)\n# Set an attribute for the stoichiometric vector\nself.stoich_vector = np.array(list(self.composition.values()))\n# Set an attribute for the normalised stoichiometric vector\nself.norm_stoich_vector = self.stoich_vector / self._natoms\n</code></pre>"},{"location":"python_api/composition/#elementembeddings.composition.CompositionalEmbedding.as_dict","title":"<code>as_dict()</code>","text":"<p>Return the CompositionalEmbedding class as a dict.</p> Source code in <code>src/elementembeddings/composition.py</code> <pre><code>def as_dict(self) -&gt; dict:\n# TO-DO: Need to create a dict representation for the embedding class\n\"\"\"Return the CompositionalEmbedding class as a dict.\"\"\"\nreturn {\n\"formula\": self.formula,\n\"composition\": self.composition,\n\"fractional_composition\": self.fractional_composition,\n# 'embedding':self.embedding.as_\n}\n# Se\n# Set an attribute\npass\n</code></pre>"},{"location":"python_api/composition/#elementembeddings.composition.CompositionalEmbedding.distance","title":"<code>distance(comp_other, distance_metric='euclidean', stats='mean')</code>","text":"<p>Compute the distance between two compositions.</p> <p>Parameters:</p> Name Type Description Default <code>comp_other</code> <code>Union[str, CompositionalEmbedding]</code> <p>The other composition.</p> required <code>distance_metric</code> <code>str</code> <p>The metric to be used. The default is 'euclidean'.</p> <code>'euclidean'</code> <p>Returns:</p> Name Type Description <code>float</code> <p>The distance between the two CompositionalEmbedding objects.</p> Source code in <code>src/elementembeddings/composition.py</code> <pre><code>def distance(\nself,\ncomp_other,\ndistance_metric: str = \"euclidean\",\nstats: Union[str, List[str]] = \"mean\",\n):\n\"\"\"\n    Compute the distance between two compositions.\n    Args:\n        comp_other (Union[str, CompositionalEmbedding]): The other composition.\n        distance_metric (str): The metric to be used. The default is 'euclidean'.\n    Returns:\n        float: The distance between the two CompositionalEmbedding objects.\n    \"\"\"\nif isinstance(comp_other, str):\ncomp_other = CompositionalEmbedding(comp_other, self.embedding)\nif not isinstance(comp_other, CompositionalEmbedding):\nraise ValueError(\n\"comp_other must be a string or a CompositionalEmbedding object.\"\n)\nif self.embedding_name != comp_other.embedding_name:\nraise ValueError(\n\"The two CompositionalEmbedding objects must have the same embedding.\"\n)\nreturn _composition_distance(\nself, comp_other, self.embedding, distance_metric, stats\n)\n</code></pre>"},{"location":"python_api/composition/#elementembeddings.composition.CompositionalEmbedding.feature_vector","title":"<code>feature_vector(stats='mean')</code>","text":"<p>Compute a feature vector.</p> <p>The feature vector is a concatenation of the statistics specified in the stats argument.</p> <p>Parameters:</p> Name Type Description Default <code>stats</code> <code>list</code> <p>A list of strings specifying the statistics to be computed.</p> <code>'mean'</code> <p>Returns:</p> Type Description <p>np.ndarray: A feature vector of dimension (len(stats) * embedding_dim).</p> Source code in <code>src/elementembeddings/composition.py</code> <pre><code>def feature_vector(self, stats: Union[str, list] = \"mean\"):\n\"\"\"\n    Compute a feature vector.\n    The feature vector is a concatenation of\n    the statistics specified in the stats argument.\n    Args:\n        stats (list): A list of strings specifying the statistics to be computed.\n        The default is ['mean'].\n    Returns:\n        np.ndarray: A feature vector of dimension (len(stats) * embedding_dim).\n    \"\"\"\nimplemented_stats = [\n\"mean\",\n\"variance\",\n\"minpool\",\n\"maxpool\",\n\"range\",\n\"sum\",\n\"geometric_mean\",\n\"harmonic_mean\",\n]\nif isinstance(stats, str):\nstats = [stats]\nif not isinstance(stats, list):\nraise ValueError(\"Stats argument must be a list of strings\")\nif not all([isinstance(s, str) for s in stats]):\nraise ValueError(\"Stats argument must be a list of strings\")\nif not all([s in implemented_stats for s in stats]):\nraise ValueError(\nf\" {[stat for stat in stats if stat not in implemented_stats]} \"\n\"are not valid statistics.\"\n)\nfeature_vector = []\nfor s in stats:\nfeature_vector.append(getattr(self, self._stats_functions_dict[s])())\nreturn np.concatenate(feature_vector)\n</code></pre>"},{"location":"python_api/composition/#elementembeddings.composition.composition_featuriser","title":"<code>composition_featuriser(data, embedding='magpie', stats='mean', inplace=False)</code>","text":"<p>Compute a feature vector for a composition.</p> <p>The feature vector is based on the statistics specified in the stats argument.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>Union[pd.DataFrame, pd.Series, list, CompositionalEmbedding]</code> required <code>embedding</code> <code>Union[Embedding, str]</code> <p>A Embedding class or a string</p> <code>'magpie'</code> <code>stats</code> <code>Union[str, list]</code> <p>A list of statistics to be computed.</p> <code>'mean'</code> <code>inplace</code> <code>bool</code> <p>Whether to perform the operation in place on the data.</p> <code>False</code> <p>Returns:</p> Type Description <code>pd.DataFrame</code> <p>Union[pd.DataFrame,list]: A pandas DataFrame containing the feature vector,</p> <code>pd.DataFrame</code> <p>or a list of feature vectors is returned</p> Source code in <code>src/elementembeddings/composition.py</code> <pre><code>def composition_featuriser(\ndata: Union[pd.DataFrame, pd.Series, CompositionalEmbedding, list],\nembedding: Union[Embedding, str] = \"magpie\",\nstats: Union[str, list] = \"mean\",\ninplace: bool = False,\n) -&gt; pd.DataFrame:\n\"\"\"\n    Compute a feature vector for a composition.\n    The feature vector is based on the statistics specified\n    in the stats argument.\n    Args:\n        data (Union[pd.DataFrame, pd.Series, list, CompositionalEmbedding]):\n        A pandas DataFrame or Series containing a column named 'formula',\n        a list of formula, or a CompositionalEmbedding class\n        embedding (Union[Embedding, str], optional): A Embedding class or a string\n        stats (Union[str, list], optional): A list of statistics to be computed.\n        The default is ['mean'].\n        inplace (bool, optional): Whether to perform the operation in place on the data.\n        The default is False.\n    Returns:\n        Union[pd.DataFrame,list]: A pandas DataFrame containing the feature vector,\n        or a list of feature vectors is returned\n    \"\"\"\nif isinstance(stats, str):\nstats = [stats]\nif isinstance(data, pd.Series):\ndata = data.to_frame(name=\"formula\")\nif isinstance(data, pd.DataFrame):\nif not inplace:\ndata = data.copy()\nif \"formula\" not in data.columns:\nraise ValueError(\n\"The data must contain a column named 'formula' to featurise.\"\n)\nprint(\"Featurising compositions...\")\ncomps = [\nCompositionalEmbedding(x, embedding) for x in tqdm(data[\"formula\"].tolist())\n]\nprint(\"Computing feature vectors...\")\nfvs = [x.feature_vector(stats) for x in tqdm(comps)]\nfeature_names = comps[0].embedding.feature_labels\nfeature_names = [\nf\"{stat}_{feature}\" for stat in stats for feature in feature_names\n]\ndata_new = pd.concat([data, pd.DataFrame(fvs, columns=feature_names)], axis=1)\n# data.columns = []\nreturn data_new\nelif isinstance(data, list):\ncomps = [CompositionalEmbedding(x, embedding) for x in data]\nreturn [x.feature_vector(stats) for x in tqdm(comps)]\nelif isinstance(data, CompositionalEmbedding):\nreturn data.feature_vector(stats)\nelse:\nraise ValueError(\n\"The data must be a pandas DataFrame, Series, \"\n\"list or CompositionalEmbedding class.\"\n)\n</code></pre>"},{"location":"python_api/composition/#elementembeddings.composition.formula_parser","title":"<code>formula_parser(formula)</code>","text":"<p>Parse a string formula.</p> <p>Returns a dictionary of the composition with key:value pairs of element symbol:amount.</p> <p>Parameters:</p> Name Type Description Default <code>formula</code> <code>str</code> <p>A string formula e.g. CsPbI3, Li7La3Zr2O12</p> required <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary of the composition</p> Source code in <code>src/elementembeddings/composition.py</code> <pre><code>def formula_parser(formula: str) -&gt; Dict[str, float]:\n# TO-DO: Add validation to check composition contains real elements.\n\"\"\"\n    Parse a string formula.\n    Returns a dictionary of the composition with key:value pairs\n    of element symbol:amount.\n    Args:\n        formula (str): A string formula e.g. CsPbI3, Li7La3Zr2O12\n    Returns:\n        (dict): A dictionary of the composition\n    \"\"\"\n# For Metallofullerene\nformula = formula.replace(\"@\", \"\")\nregex = r\"\\(([^\\(\\)]+)\\)\\s*([\\.e\\d]*)\"\nr = re.compile(regex)\nm = re.search(r, formula)\nif m:\nfactor = 1.0\nif m.group(2) != \"\":\nfactor = float(m.group(2))\nunit_sym_dict = _get_sym_dict(m.group(1), factor)\nexpanded_sym = \"\".join([f\"{el}{amt}\" for el, amt in unit_sym_dict.items()])\nexpanded_formula = formula.replace(m.group(), expanded_sym)\nreturn formula_parser(expanded_formula)\nreturn _get_sym_dict(formula, 1)\n</code></pre>"},{"location":"python_api/core/","title":"Core module","text":"<p>Provides the <code>Embedding</code> class.</p> <p>This module enables the user load in elemetal representation data and analyse it using statistical functions.</p> Typical usage example <p>megnet16 = Embedding.load_data('megnet16')</p>"},{"location":"python_api/core/#elementembeddings.core.Embedding","title":"<code>Embedding</code>","text":"<p>Represent an elemental representation.</p> <p>To load an embedding distributed from the package use the load_data() method.</p> <p>Works like a standard python dictionary. The keys are {element: vector} pairs.</p> <p>Adds a few convenience methods related to elemental representations.</p> Source code in <code>src/elementembeddings/core.py</code> <pre><code>class Embedding:\n\"\"\"\n    Represent an elemental representation.\n    To load an embedding distributed from the package use the load_data() method.\n    Works like a standard python dictionary. The keys are {element: vector} pairs.\n    Adds a few convenience methods related to elemental representations.\n    \"\"\"\ndef __init__(\nself,\nembeddings: dict,\nembedding_name: Optional[str] = None,\nfeature_labels: Optional[List[str]] = None,\n):\n\"\"\"Initialise the Embedding class.\n        Args:\n            embeddings (dict): A {element_symbol: vector} dictionary\n            embedding_name (str): The name of the elemental representation\n            feature_labels (list(str)): A list of feature labels\n        \"\"\"\nself.embeddings = embeddings\nself.embedding_name = embedding_name\nself.feature_labels = feature_labels\nif not self._is_standardised():\nwarnings.warn(\n\"Embedding is not standardised. \"\n\"It is recommended that you standardise your embeddings before use. \"\n\"Use the standardise() method to standardise your embeddings.\"\n)\nself.is_standardised = False\nelse:\nself.is_standardised = True\n# Grab a random value from the embedding vector\n_rand_embed = random.choice(list(self.embeddings.values()))\n# Convert embeddings to numpy array if not already a numpy array\nif not isinstance(_rand_embed, np.ndarray):\nself.embeddings = {\nele: np.array(self.embeddings[ele]) for ele in self.embeddings\n}\n# Determines if the embedding vector has a length attribute\n# (i.e. is not a scalar int or float)\n# If the 'vector' is a scalar/float, the representation is linear\n# A linear representation gets converted to a one-hot vector\nif hasattr(_rand_embed, \"__len__\") and (not isinstance(_rand_embed, str)):\nself.embedding_type: str = \"vector\"\nself.dim: int = len(random.choice(list(self.embeddings.values())))\nelse:\nself.embedding_type: str = \"linear\"\n# Create one-hot vectors for a scalar representation\nif self.embedding_type == \"linear\":\nsorted_embedding = sorted(self.embeddings.items(), key=lambda x: x[1])\nelements = np.loadtxt(\nf\"{data_directory}/element_data/ordered_periodic.txt\", dtype=str\n)\nif self.embedding_name == \"mod_petti\":\nsorted_embedding = {\nel: num for el, num in sorted_embedding if el in elements[:103]\n}\nelse:\nsorted_embedding = {\nel: num for el, num in sorted_embedding if el in elements[:118]\n}\nself.feature_labels = list(sorted_embedding.keys())\nself.embeddings = {}\nfor el, num in sorted_embedding.items():\nself.embeddings[el] = np.zeros(len(sorted_embedding))\nself.embeddings[el][num] = 1\nself.dim = len(random.choice(list(self.embeddings.values())))\nif not self.feature_labels:\nself.feature_labels = list(range(self.dim))\nelse:\nself.feature_labels = self.feature_labels\n# Dummy initialisation for results\nself._data = []\nself._pca_data = None  # type: Optional[np.ndarray]\nself._tsne_data = None  # type: Optional[np.ndarray]\nself._umap_data = None  # type: Optional[np.ndarray]\n@staticmethod\ndef load_data(embedding_name: Optional[str] = None):\n\"\"\"\n        Create an instance of the `Embedding` class from a default embedding file.\n        The default embeddings are in the table below:\n        | **Name**                | **str_name** |\n        |-------------------------|--------------|\n        | Magpie                  | magpie       |\n        | Magpie (scaled)         | magpie_sc    |\n        | Mat2Vec                 | mat2vec      |\n        | Matscholar              | matscholar   |\n        | Megnet (16 dimensions)  | megnet16     |\n        | Modified pettifor scale | mod_petti    |\n        | Oliynyk                 | oliynyk      |\n        | Oliynyk (scaled)        | oliynyk_sc   |\n        | Random (200 dimensions) | random_200   |\n        | SkipAtom                | skipatom     |\n        | Atomic Number           | atomic       |\n        Args:\n            embedding_name (str): The str_name of an embedding file.\n        Returns:\n            Embedding :class:`Embedding` instance.\n        \"\"\"\n_cbfv_files = {\n\"magpie\": \"magpie.csv\",\n\"magpie_sc\": \"magpie_sc.json\",\n\"mat2vec\": \"mat2vec.csv\",\n\"matscholar\": \"matscholar-embedding.json\",\n\"megnet16\": \"megnet16.json\",\n\"mod_petti\": \"mod_petti.json\",\n\"oliynyk\": \"oliynyk.csv\",\n\"oliynyk_sc\": \"oliynyk_sc.json\",\n\"random_200\": \"random_200_new.csv\",\n\"skipatom\": \"skipatom_20201009_induced.csv\",\n\"atomic\": \"atomic.json\",\n}\nif _cbfv_files[embedding_name].endswith(\".csv\"):\nreturn Embedding.from_csv(\npath.join(\ndata_directory,\n\"element_representations\",\n_cbfv_files[embedding_name],\n),\nembedding_name,\n)\nelif \"megnet\" in _cbfv_files[embedding_name]:\nreturn Embedding.from_json(\npath.join(\ndata_directory,\n\"element_representations\",\n_cbfv_files[embedding_name],\n),\nembedding_name,\n).remove_elements([\"Null\"])\nelif _cbfv_files[embedding_name].endswith(\".json\"):\nreturn Embedding.from_json(\npath.join(\ndata_directory,\n\"element_representations\",\n_cbfv_files[embedding_name],\n),\nembedding_name,\n)\n@staticmethod\ndef from_json(embedding_json, embedding_name: Optional[str] = None):\n\"\"\"\n        Create an instance of the Embedding class from a json file.\n        Args:\n            embedding_json (str): Filepath of the json file\n            embedding_name (str): The name of the elemental representation\n        \"\"\"\n# Need to add validation handling for JSONs in different formats\nwith open(embedding_json) as f:\nembedding_data = json.load(f)\nreturn Embedding(embedding_data, embedding_name)\n@staticmethod\ndef from_csv(embedding_csv, embedding_name: Optional[str] = None):\n\"\"\"\n        Create an instance of the Embedding class from a csv file.\n        The first column of the csv file must contain the elements and be named element.\n        Args:\n            embedding_csv (str): Filepath of the csv file\n            embedding_name (str): The name of the elemental representation\n        \"\"\"\n# Need to add validation handling for csv files\ndf = pd.read_csv(embedding_csv)\nelements = list(df[\"element\"])\ndf.drop([\"element\"], axis=1, inplace=True)\nfeature_labels = list(df.columns)\nembeds_array = df.to_numpy()\nembedding_data = {\nelements[i]: embeds_array[i] for i in range(len(embeds_array))\n}\nreturn Embedding(embedding_data, embedding_name, feature_labels)\ndef as_dataframe(self, columns: str = \"components\") -&gt; pd.DataFrame:\n\"\"\"\n        Return the embedding as a pandas Dataframe.\n        The first column is the elements and each other\n        column represents a component of the embedding.\n        Args:\n            columns (str): A string to specify if the columns are the vector components\n            and the index is the elements (`columns='components'`)\n            or the columns are the elements (`columns='elements'`).\n        Returns:\n            df (pandas.DataFrame): A pandas dataframe object\n        \"\"\"\nembedding = self.embeddings\ndf = pd.DataFrame(embedding, index=self.feature_labels)\nif columns == \"components\":\nreturn df.T\nelif columns == \"elements\":\nreturn df\nelse:\nraise (\nValueError(\nf\"{columns} is not a valid keyword argument. \"\n\"Choose either 'components' or 'elements\"\n)\n)\ndef to(self, fmt: str = \"\", filename: Optional[str] = \"\"):\n\"\"\"\n        Output the embedding to a file.\n        Args:\n            fmt (str): The file format to output the embedding to.\n            Options include \"json\" and \"csv\".\n            filename (str): The name of the file to be outputted\n        Returns:\n            (str) if filename not specified, otherwise None.\n        \"\"\"\nfmt = fmt.lower()\nif fmt == \"json\" or fnmatch.fnmatch(filename, \"*.json\"):\nj = json.dumps(self.embeddings, cls=NumpyEncoder)\nif filename:\nif not filename.endswith(\".json\"):\nfilename = filename + \".json\"\nwith open(filename, \"w\") as file:\nfile.write(j)\nelse:\nreturn j\nelif fmt == \"csv\" or fnmatch.fnmatch(filename, \"*.csv\"):\nif filename:\nif not filename.endswith(\".csv\"):\nfilename = filename + \".csv\"\nself.as_dataframe().to_csv(filename, index_label=\"element\")\nelse:\nreturn self.as_dataframe().to_csv(index_label=\"element\")\nelse:\nraise ValueError(f\"{str(fmt)} is an invalid file format\")\n@property\ndef element_list(self) -&gt; list:\n\"\"\"Return the elements of the embedding.\"\"\"\nreturn list(self.embeddings.keys())\ndef remove_elements(self, elements: Union[str, List[str]], inplace: bool = False):\n# TO-DO allow removal by atomic numbers\n\"\"\"\n        Remove elements from the Embedding instance.\n        Args:\n            elements (str,list(str)): An element symbol or a list of element symbols\n            inplace (bool): If True, elements are removed from the Embedding instance.\n            If false, the original embedding instance is unchanged\n            and a new embedding instance with the elements removed is created.\n        \"\"\"\nif inplace:\nif isinstance(elements, str):\ndel self.embeddings[elements]\nelif isinstance(elements, list):\nfor el in elements:\ndel self.embeddings[el]\nreturn None\nelse:\nembeddings_copy = self.embeddings.copy()\nif isinstance(elements, str):\ndel embeddings_copy[elements]\nelif isinstance(elements, list):\nfor el in elements:\ndel embeddings_copy[el]\nreturn Embedding(embeddings_copy, self.embedding_name)\ndef _is_standardised(self):\n\"\"\"Check if the embeddings are standardised.\n        Mean must be 0 and standard deviation must be 1.\n        \"\"\"\nreturn np.isclose(\nnp.mean(np.array(list(self.embeddings.values()))), 0\n) and np.isclose(np.std(np.array(list(self.embeddings.values()))), 1)\ndef standardise(self, inplace: bool = False):\n\"\"\"Standardise the embeddings.\n        Mean is 0 and standard deviation is 1.\n        \"\"\"\nif self._is_standardised():\nwarnings.warn(\n\"Embedding is already standardised. \"\n\"Returning None and not changing the embedding.\"\n)\nreturn None\nelse:\nembeddings_copy = self.embeddings.copy()\nembeddings_array = np.array(list(embeddings_copy.values()))\nembeddings_array = StandardScaler().fit_transform(embeddings_array)\nfor el, emb in zip(embeddings_copy.keys(), embeddings_array):\nembeddings_copy[el] = emb\nif inplace:\nself.embeddings = embeddings_copy\nself.is_standardised = True\nreturn None\nelse:\nreturn Embedding(embeddings_copy, self.embedding_name)\ndef citation(self) -&gt; List[str]:\n\"\"\"Return a citation for the embedding.\"\"\"\nif self.embedding_name in [\"magpie\", \"magpie_sc\"]:\ncitation = [\n\"@article{ward2016general,\"\n\"title={A general-purpose machine learning framework for \"\n\"predicting properties of inorganic materials},\"\n\"author={Ward, Logan and Agrawal, Ankit and Choudhary, Alok \"\n\"and Wolverton, Christopher},\"\n\"journal={npj Computational Materials},\"\n\"volume={2},\"\n\"number={1},\"\n\"pages={1--7},\"\n\"year={2016},\"\n\"publisher={Nature Publishing Group}}\"\n]\nelif self.embedding_name == \"mat2vec\":\ncitation = [\n\"@article{tshitoyan2019unsupervised,\"\n\"title={Unsupervised word embeddings capture latent knowledge \"\n\"from materials science literature},\"\n\"author={Tshitoyan, Vahe and Dagdelen, John and Weston, Leigh \"\n\"and Dunn, Alexander and Rong, Ziqin and Kononova, Olga \"\n\"and Persson, Kristin A and Ceder, Gerbrand and Jain, Anubhav},\"\n\"journal={Nature},\"\n\"volume={571},\"\n\"number={7763},\"\n\"pages={95--98},\"\n\"year={2019},\"\n\"publisher={Nature Publishing Group} }\"\n]\nelif self.embedding_name == \"matscholar\":\ncitation = [\n\"@article{weston2019named,\"\n\"title={Named entity recognition and normalization applied to \"\n\"large-scale information extraction from the materials \"\n\"science literature},\"\n\"author={Weston, Leigh and Tshitoyan, Vahe and Dagdelen, John and \"\n\"Kononova, Olga and Trewartha, Amalie and Persson, Kristin A and \"\n\"Ceder, Gerbrand and Jain, Anubhav},\"\n\"journal={Journal of chemical information and modeling},\"\n\"volume={59},\"\n\"number={9},\"\n\"pages={3692--3702},\"\n\"year={2019},\"\n\"publisher={ACS Publications} }\"\n]\nelif self.embedding_name == \"megnet16\":\ncitation = [\n\"@article{chen2019graph,\"\n\"title={Graph networks as a universal machine learning framework \"\n\"for molecules and crystals},\"\n\"author={Chen, Chi and Ye, Weike and Zuo, Yunxing and \"\n\"Zheng, Chen and Ong, Shyue Ping},\"\n\"journal={Chemistry of Materials},\"\n\"volume={31},\"\n\"number={9},\"\n\"pages={3564--3572},\"\n\"year={2019},\"\n\"publisher={ACS Publications} }\"\n]\nelif self.embedding_name in [\"oliynyk\", \"oliynyk_sc\"]:\ncitation = [\n\"              @article{oliynyk2016high,\"\n\"title={High-throughput machine-learning-driven synthesis \"\n\"of full-Heusler compounds},\"\n\"author={Oliynyk, Anton O and Antono, Erin and Sparks, Taylor D and \"\n\"Ghadbeigi, Leila and Gaultois, Michael W and \"\n\"Meredig, Bryce and Mar, Arthur},\"\n\"journal={Chemistry of Materials},\"\n\"volume={28},\"\n\"number={20},\"\n\"pages={7324--7331},\"\n\"year={2016},\"\n\"publisher={ACS Publications} }\"\n]\nelif self.embedding_name == \"skipatom\":\ncitation = [\n\"@article{antunes2022distributed,\"\n\"title={Distributed representations of atoms and materials \"\n\"for machine learning},\"\n\"author={Antunes, Luis M and Grau-Crespo, Ricardo and Butler, Keith T},\"\n\"journal={npj Computational Materials},\"\n\"volume={8},\"\n\"number={1},\"\n\"pages={1--9},\"\n\"year={2022},\"\n\"publisher={Nature Publishing Group} }\"\n]\nelif self.embedding_name == \"mod_petti\":\ncitation = [\n\"@article{glawe2016optimal,\"\n\"title={The optimal one dimensional periodic table: \"\n\"a modified Pettifor chemical scale from data mining},\"\n\"author={Glawe, Henning and Sanna, Antonio and Gross, \"\n\"EKU and Marques, Miguel AL},\"\n\"journal={New Journal of Physics},\"\n\"volume={18},\"\n\"number={9},\"\n\"pages={093011},\"\n\"year={2016},\"\n\"publisher={IOP Publishing} }\"\n]\nelse:\ncitation = []\nreturn citation\ndef _is_el_in_embedding(self, el: str) -&gt; bool:\n\"\"\"\n        Check if an element is in the `Embedding` object.\n        Args:\n            el (str): An element symbol\n        Returns:\n            bool: True if el is in the Embedding, else False\n        \"\"\"\nif el in self.element_list:\nreturn True\nelse:\nreturn False\n@property\ndef element_groups_dict(self) -&gt; Dict[str, str]:\n\"\"\"\n        Return a dictionary of {element: element type} pairs.\n        e.g. {'He':'Noble gas'}\n        \"\"\"\nwith open(path.join(data_directory, \"element_data/element_group.json\")) as f:\n_dict = json.load(f)\nreturn {i: _dict[i] for i in self.element_list}\ndef create_pairs(self):\n\"\"\"Create all possible pairs of elements.\"\"\"\nele_list = self.element_list\nele_pairs = combinations_with_replacement(ele_list, 2)\nreturn ele_pairs\ndef compute_correlation_metric(\nself, ele1: str, ele2: str, metric: str = \"pearson\"\n) -&gt; float:\n\"\"\"\n        Compute the correlation/similarity metric between two vectors.\n        Allowed metrics:\n        * Pearson\n        * Spearman\n        * Cosine similarity\n        Args:\n            ele1 (str): element symbol\n            ele2 (str): element symbol\n            metric (str): name of a correlation metric.\n            Options are \"spearman\", \"pearson\" and \"cosine_similarity\".\n        Returns:\n            float: correlation/similarity metric\n        \"\"\"\n# Define the allowable metrics\nscipy_corrs = {\"pearson\": pearsonr, \"spearman\": spearmanr}\nif metric == \"pearson\":\nreturn scipy_corrs[metric](\nself.embeddings[ele1], self.embeddings[ele2]\n).statistic\nelif metric == \"spearman\":\nreturn scipy_corrs[metric](\nself.embeddings[ele1], self.embeddings[ele2]\n).correlation\nelif metric == \"cosine_similarity\":\nreturn cosine_similarity(self.embeddings[ele1], self.embeddings[ele2])\ndef compute_distance_metric(\nself, ele1: str, ele2: str, metric: str = \"euclidean\"\n) -&gt; float:\n\"\"\"\n        Compute distance metric between two vectors.\n        Allowed metrics:\n        * euclidean\n        * manhattan\n        * chebyshev\n        * wasserstein\n        * energy\n        * cosine_distance\n        Args:\n            ele1 (str): element symbol\n            ele2 (str): element symbol\n            metric (str): name of a distance metric\n        Returns:\n            distance (float): distance between embedding vectors\n        \"\"\"\n# Define the allowable metrics\nscikit_metrics = [\"euclidean\", \"manhattan\", \"chebyshev\"]\nscipy_metrics = {\"wasserstein\": wasserstein_distance, \"energy\": energy_distance}\nvalid_metrics = scikit_metrics + list(scipy_metrics.keys()) + [\"cosine\"]\n# Validate if the elements are within the embedding vector\nif not all([self._is_el_in_embedding(ele1), self._is_el_in_embedding(ele2)]):\nif not self._is_el_in_embedding(ele1):\nprint(f\"{ele1} is not an element included within the atomic embeddings\")\nraise ValueError\nelif not self._is_el_in_embedding(ele2):\nprint(f\"{ele2} is not an element included within the atomic embeddings\")\nraise ValueError\n# Compute the distance measure\nif metric in scikit_metrics:\ndistance = DistanceMetric.get_metric(metric)\nreturn distance.pairwise(\nself.embeddings[ele1].reshape(1, -1),\nself.embeddings[ele2].reshape(1, -1),\n)[0][0]\nelif metric in scipy_metrics.keys():\nreturn scipy_metrics[metric](self.embeddings[ele1], self.embeddings[ele2])\nelif metric == \"cosine_distance\":\nreturn cosine_distance(self.embeddings[ele1], self.embeddings[ele2])\nelse:\nprint(\n\"Invalid distance metric.\"\nf\"Use one of the following metrics:{valid_metrics}\"\n)\nraise ValueError\ndef distance_df(self, metric: str = \"euclidean\") -&gt; pd.DataFrame:\n\"\"\"\n        Return a dataframe with columns [\"ele_1\", \"ele_2\", metric].\n        Allowed metrics:\n        * euclidean\n        * manhattan\n        * chebyshev\n        * wasserstein\n        * energy\n        Args:\n            metric (str): A distance metric.\n        Returns:\n            df (pandas.DataFrame): A dataframe with columns [\"ele_1\", \"ele_2\", metric].\n        \"\"\"\nele_pairs = self.create_pairs()\ntable = []\nfor ele1, ele2 in ele_pairs:\ndist = self.compute_distance_metric(ele1, ele2, metric=metric)\ntable.append((ele1, ele2, dist))\nif ele1 != ele2:\ntable.append((ele2, ele1, dist))\ncorr_df = pd.DataFrame(table, columns=[\"ele_1\", \"ele_2\", metric])\nmend_1 = [(Element(ele).mendeleev_no, ele) for ele in corr_df[\"ele_1\"]]\nmend_2 = [(Element(ele).mendeleev_no, ele) for ele in corr_df[\"ele_2\"]]\nZ_1 = [(pt[ele][\"number\"], ele) for ele in corr_df[\"ele_1\"]]\nZ_2 = [(pt[ele][\"number\"], ele) for ele in corr_df[\"ele_2\"]]\ncorr_df[\"mend_1\"] = mend_1\ncorr_df[\"mend_2\"] = mend_2\ncorr_df[\"Z_1\"] = Z_1\ncorr_df[\"Z_2\"] = Z_2\ncorr_df = corr_df[[\"ele_1\", \"ele_2\", \"mend_1\", \"mend_2\", \"Z_1\", \"Z_2\", metric]]\nreturn corr_df\ndef correlation_df(self, metric: str = \"pearson\") -&gt; pd.DataFrame:\n\"\"\"\n        Return a dataframe with columns [\"ele_1\", \"ele_2\", metric].\n        Allowed metrics:\n        * pearson\n        * spearman\n        * cosine_similarity\n        Args:\n            metric (str): A distance metric.\n        Returns:\n            df (pandas.DataFrame): A dataframe with columns [\"ele_1\", \"ele_2\", metric].\n        \"\"\"\nele_pairs = self.create_pairs()\ntable = []\nfor ele1, ele2 in ele_pairs:\ndist = self.compute_correlation_metric(ele1, ele2, metric=metric)\ntable.append((ele1, ele2, dist))\nif ele1 != ele2:\ntable.append((ele2, ele1, dist))\ncorr_df = pd.DataFrame(table, columns=[\"ele_1\", \"ele_2\", metric])\nmend_1 = [(Element(ele).mendeleev_no, ele) for ele in corr_df[\"ele_1\"]]\nmend_2 = [(Element(ele).mendeleev_no, ele) for ele in corr_df[\"ele_2\"]]\nZ_1 = [(pt[ele][\"number\"], ele) for ele in corr_df[\"ele_1\"]]\nZ_2 = [(pt[ele][\"number\"], ele) for ele in corr_df[\"ele_2\"]]\ncorr_df[\"mend_1\"] = mend_1\ncorr_df[\"mend_2\"] = mend_2\ncorr_df[\"Z_1\"] = Z_1\ncorr_df[\"Z_2\"] = Z_2\ncorr_df = corr_df[[\"ele_1\", \"ele_2\", \"mend_1\", \"mend_2\", \"Z_1\", \"Z_2\", metric]]\nreturn corr_df\ndef distance_pivot_table(\nself, metric: str = \"euclidean\", sortby: str = \"mendeleev\"\n) -&gt; pd.DataFrame:\n\"\"\"\n        Return a pandas.DataFrame style pivot.\n        The index and column being either the mendeleev number or atomic number\n        of the element pairs and the values being a user-specified distance metric.\n        Args:\n            metric (str): A distance metric.\n            sortby (str): Sort the pivot table by either \"mendeleev\" or \"atomic_number\".\n        Returns:\n            distance_pivot (pandas.DataFrame): A pandas DataFrame pivot table.\n        \"\"\"\ncorr_df = self.distance_df(metric=metric)\nif sortby == \"mendeleev\":\ndistance_pivot = corr_df.pivot_table(\nvalues=metric, index=\"mend_1\", columns=\"mend_2\"\n)\nreturn distance_pivot\nelif sortby == \"atomic_number\":\ndistance_pivot = corr_df.pivot_table(\nvalues=metric, index=\"Z_1\", columns=\"Z_2\"\n)\nreturn distance_pivot\ndef correlation_pivot_table(\nself, metric: str = \"pearson\", sortby: str = \"mendeleev\"\n) -&gt; pd.DataFrame:\n\"\"\"\n        Return a pandas.DataFrame style pivot.\n        The index and column being either the mendeleev number or atomic number\n        of the element pairs and the values being a user-specified distance metric.\n        Args:\n            metric (str): A distance metric.\n            sortby (str): Sort the pivot table by either \"mendeleev\" or \"atomic_number\".\n        Returns:\n            distance_pivot (pandas.DataFrame): A pandas DataFrame pivot table.\n        \"\"\"\ncorr_df = self.correlation_df(metric=metric)\nif sortby == \"mendeleev\":\ncorrelation_pivot = corr_df.pivot_table(\nvalues=metric, index=\"mend_1\", columns=\"mend_2\"\n)\nreturn correlation_pivot\nelif sortby == \"atomic_number\":\ncorrelation_pivot = corr_df.pivot_table(\nvalues=metric, index=\"Z_1\", columns=\"Z_2\"\n)\nreturn correlation_pivot\ndef calculate_PC(self, n_components: int = 2, standardise: bool = True, **kwargs):\n\"\"\"Calculate the principal componenets (PC) of the embeddings.\n        Args:\n            n_components (int): The number of components to project the embeddings to.\n            standardise (bool): Whether to standardise the embeddings before projecting.\n            **kwargs: Other keyword arguments to be passed to PCA.\n        \"\"\"\nif standardise:\nif self.is_standardised:\nembeddings_array = np.array(list(self.embeddings.values()))\nelse:\nself.standardise(inplace=True)\nembeddings_array = np.array(list(self.embeddings.values()))\nelse:\nwarnings.warn(\n\"\"\"It is recommended to scale the embeddings\n                before projecting with PCA.\n                To do so, set `standardise=True`.\"\"\"\n)\nembeddings_array = np.array(list(self.embeddings.values()))\npca = decomposition.PCA(\nn_components=n_components, **kwargs\n)  # project to N dimensions\npca.fit(embeddings_array)\nself._pca_data = pca.transform(embeddings_array)\nreturn self._pca_data\ndef calculate_tSNE(self, n_components: int = 2, standardise: bool = True, **kwargs):\n\"\"\"Calculate t-SNE components.\n        Args:\n            n_components (int): The number of components to project the embeddings to.\n            standardise (bool): Whether to standardise the embeddings before projecting.\n            **kwargs: Other keyword arguments to be passed to t-SNE.\n        \"\"\"\nif standardise:\nif self.is_standardised:\nembeddings_array = np.array(list(self.embeddings.values()))\nelse:\nself.standardise(inplace=True)\nembeddings_array = np.array(list(self.embeddings.values()))\nelse:\nwarnings.warn(\n\"\"\"It is recommended to scale the embeddings\n                before projecting with t-SNE.\n                To do so, set `standardise=True`.\"\"\"\n)\nembeddings_array = np.array(list(self.embeddings.values()))\ntsne = TSNE(n_components=n_components, **kwargs)\ntsne_result = tsne.fit_transform(embeddings_array)\nself._tsne_data = tsne_result\nreturn self._tsne_data\ndef calculate_UMAP(self, n_components: int = 2, standardise: bool = True, **kwargs):\n\"\"\"Calculate UMAP embeddings.\n        Args:\n            n_components (int): The number of components to project the embeddings to.\n            standardise (bool): Whether to scale the embeddings before projecting.\n            **kwargs: Other keyword arguments to be passed to UMAP.\n        \"\"\"\nif standardise:\nif self.is_standardised:\nembeddings_array = np.array(list(self.embeddings.values()))\nelse:\nself.standardise(inplace=True)\nembeddings_array = np.array(list(self.embeddings.values()))\nelse:\nwarnings.warn(\n\"\"\"It is recommended to scale the embeddings\n                before projecting with UMAP.\n                To do so, set `standardise=True`.\"\"\"\n)\nembeddings_array = np.array(list(self.embeddings.values()))\numap = UMAP(n_components=n_components, **kwargs)\numap_result = umap.fit_transform(embeddings_array)\nself._umap_data = umap_result\nreturn self._umap_data\n</code></pre>"},{"location":"python_api/core/#elementembeddings.core.Embedding.element_groups_dict","title":"<code>element_groups_dict: Dict[str, str]</code>  <code>property</code>","text":"<p>Return a dictionary of {element: element type} pairs.</p> <p>e.g. {'He':'Noble gas'}</p>"},{"location":"python_api/core/#elementembeddings.core.Embedding.element_list","title":"<code>element_list: list</code>  <code>property</code>","text":"<p>Return the elements of the embedding.</p>"},{"location":"python_api/core/#elementembeddings.core.Embedding.__init__","title":"<code>__init__(embeddings, embedding_name=None, feature_labels=None)</code>","text":"<p>Initialise the Embedding class.</p> <p>Parameters:</p> Name Type Description Default <code>embeddings</code> <code>dict</code> <p>A {element_symbol: vector} dictionary</p> required <code>embedding_name</code> <code>str</code> <p>The name of the elemental representation</p> <code>None</code> <code>feature_labels</code> <code>list(str</code> <p>A list of feature labels</p> <code>None</code> Source code in <code>src/elementembeddings/core.py</code> <pre><code>def __init__(\nself,\nembeddings: dict,\nembedding_name: Optional[str] = None,\nfeature_labels: Optional[List[str]] = None,\n):\n\"\"\"Initialise the Embedding class.\n    Args:\n        embeddings (dict): A {element_symbol: vector} dictionary\n        embedding_name (str): The name of the elemental representation\n        feature_labels (list(str)): A list of feature labels\n    \"\"\"\nself.embeddings = embeddings\nself.embedding_name = embedding_name\nself.feature_labels = feature_labels\nif not self._is_standardised():\nwarnings.warn(\n\"Embedding is not standardised. \"\n\"It is recommended that you standardise your embeddings before use. \"\n\"Use the standardise() method to standardise your embeddings.\"\n)\nself.is_standardised = False\nelse:\nself.is_standardised = True\n# Grab a random value from the embedding vector\n_rand_embed = random.choice(list(self.embeddings.values()))\n# Convert embeddings to numpy array if not already a numpy array\nif not isinstance(_rand_embed, np.ndarray):\nself.embeddings = {\nele: np.array(self.embeddings[ele]) for ele in self.embeddings\n}\n# Determines if the embedding vector has a length attribute\n# (i.e. is not a scalar int or float)\n# If the 'vector' is a scalar/float, the representation is linear\n# A linear representation gets converted to a one-hot vector\nif hasattr(_rand_embed, \"__len__\") and (not isinstance(_rand_embed, str)):\nself.embedding_type: str = \"vector\"\nself.dim: int = len(random.choice(list(self.embeddings.values())))\nelse:\nself.embedding_type: str = \"linear\"\n# Create one-hot vectors for a scalar representation\nif self.embedding_type == \"linear\":\nsorted_embedding = sorted(self.embeddings.items(), key=lambda x: x[1])\nelements = np.loadtxt(\nf\"{data_directory}/element_data/ordered_periodic.txt\", dtype=str\n)\nif self.embedding_name == \"mod_petti\":\nsorted_embedding = {\nel: num for el, num in sorted_embedding if el in elements[:103]\n}\nelse:\nsorted_embedding = {\nel: num for el, num in sorted_embedding if el in elements[:118]\n}\nself.feature_labels = list(sorted_embedding.keys())\nself.embeddings = {}\nfor el, num in sorted_embedding.items():\nself.embeddings[el] = np.zeros(len(sorted_embedding))\nself.embeddings[el][num] = 1\nself.dim = len(random.choice(list(self.embeddings.values())))\nif not self.feature_labels:\nself.feature_labels = list(range(self.dim))\nelse:\nself.feature_labels = self.feature_labels\n# Dummy initialisation for results\nself._data = []\nself._pca_data = None  # type: Optional[np.ndarray]\nself._tsne_data = None  # type: Optional[np.ndarray]\nself._umap_data = None  # type: Optional[np.ndarray]\n</code></pre>"},{"location":"python_api/core/#elementembeddings.core.Embedding.as_dataframe","title":"<code>as_dataframe(columns='components')</code>","text":"<p>Return the embedding as a pandas Dataframe.</p> <p>The first column is the elements and each other column represents a component of the embedding.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>str</code> <p>A string to specify if the columns are the vector components</p> <code>'components'</code> <p>Returns:</p> Name Type Description <code>df</code> <code>pandas.DataFrame</code> <p>A pandas dataframe object</p> Source code in <code>src/elementembeddings/core.py</code> <pre><code>def as_dataframe(self, columns: str = \"components\") -&gt; pd.DataFrame:\n\"\"\"\n    Return the embedding as a pandas Dataframe.\n    The first column is the elements and each other\n    column represents a component of the embedding.\n    Args:\n        columns (str): A string to specify if the columns are the vector components\n        and the index is the elements (`columns='components'`)\n        or the columns are the elements (`columns='elements'`).\n    Returns:\n        df (pandas.DataFrame): A pandas dataframe object\n    \"\"\"\nembedding = self.embeddings\ndf = pd.DataFrame(embedding, index=self.feature_labels)\nif columns == \"components\":\nreturn df.T\nelif columns == \"elements\":\nreturn df\nelse:\nraise (\nValueError(\nf\"{columns} is not a valid keyword argument. \"\n\"Choose either 'components' or 'elements\"\n)\n)\n</code></pre>"},{"location":"python_api/core/#elementembeddings.core.Embedding.calculate_PC","title":"<code>calculate_PC(n_components=2, standardise=True, **kwargs)</code>","text":"<p>Calculate the principal componenets (PC) of the embeddings.</p> <p>Parameters:</p> Name Type Description Default <code>n_components</code> <code>int</code> <p>The number of components to project the embeddings to.</p> <code>2</code> <code>standardise</code> <code>bool</code> <p>Whether to standardise the embeddings before projecting.</p> <code>True</code> <code>**kwargs</code> <p>Other keyword arguments to be passed to PCA.</p> <code>{}</code> Source code in <code>src/elementembeddings/core.py</code> <pre><code>def calculate_PC(self, n_components: int = 2, standardise: bool = True, **kwargs):\n\"\"\"Calculate the principal componenets (PC) of the embeddings.\n    Args:\n        n_components (int): The number of components to project the embeddings to.\n        standardise (bool): Whether to standardise the embeddings before projecting.\n        **kwargs: Other keyword arguments to be passed to PCA.\n    \"\"\"\nif standardise:\nif self.is_standardised:\nembeddings_array = np.array(list(self.embeddings.values()))\nelse:\nself.standardise(inplace=True)\nembeddings_array = np.array(list(self.embeddings.values()))\nelse:\nwarnings.warn(\n\"\"\"It is recommended to scale the embeddings\n            before projecting with PCA.\n            To do so, set `standardise=True`.\"\"\"\n)\nembeddings_array = np.array(list(self.embeddings.values()))\npca = decomposition.PCA(\nn_components=n_components, **kwargs\n)  # project to N dimensions\npca.fit(embeddings_array)\nself._pca_data = pca.transform(embeddings_array)\nreturn self._pca_data\n</code></pre>"},{"location":"python_api/core/#elementembeddings.core.Embedding.calculate_UMAP","title":"<code>calculate_UMAP(n_components=2, standardise=True, **kwargs)</code>","text":"<p>Calculate UMAP embeddings.</p> <p>Parameters:</p> Name Type Description Default <code>n_components</code> <code>int</code> <p>The number of components to project the embeddings to.</p> <code>2</code> <code>standardise</code> <code>bool</code> <p>Whether to scale the embeddings before projecting.</p> <code>True</code> <code>**kwargs</code> <p>Other keyword arguments to be passed to UMAP.</p> <code>{}</code> Source code in <code>src/elementembeddings/core.py</code> <pre><code>def calculate_UMAP(self, n_components: int = 2, standardise: bool = True, **kwargs):\n\"\"\"Calculate UMAP embeddings.\n    Args:\n        n_components (int): The number of components to project the embeddings to.\n        standardise (bool): Whether to scale the embeddings before projecting.\n        **kwargs: Other keyword arguments to be passed to UMAP.\n    \"\"\"\nif standardise:\nif self.is_standardised:\nembeddings_array = np.array(list(self.embeddings.values()))\nelse:\nself.standardise(inplace=True)\nembeddings_array = np.array(list(self.embeddings.values()))\nelse:\nwarnings.warn(\n\"\"\"It is recommended to scale the embeddings\n            before projecting with UMAP.\n            To do so, set `standardise=True`.\"\"\"\n)\nembeddings_array = np.array(list(self.embeddings.values()))\numap = UMAP(n_components=n_components, **kwargs)\numap_result = umap.fit_transform(embeddings_array)\nself._umap_data = umap_result\nreturn self._umap_data\n</code></pre>"},{"location":"python_api/core/#elementembeddings.core.Embedding.calculate_tSNE","title":"<code>calculate_tSNE(n_components=2, standardise=True, **kwargs)</code>","text":"<p>Calculate t-SNE components.</p> <p>Parameters:</p> Name Type Description Default <code>n_components</code> <code>int</code> <p>The number of components to project the embeddings to.</p> <code>2</code> <code>standardise</code> <code>bool</code> <p>Whether to standardise the embeddings before projecting.</p> <code>True</code> <code>**kwargs</code> <p>Other keyword arguments to be passed to t-SNE.</p> <code>{}</code> Source code in <code>src/elementembeddings/core.py</code> <pre><code>def calculate_tSNE(self, n_components: int = 2, standardise: bool = True, **kwargs):\n\"\"\"Calculate t-SNE components.\n    Args:\n        n_components (int): The number of components to project the embeddings to.\n        standardise (bool): Whether to standardise the embeddings before projecting.\n        **kwargs: Other keyword arguments to be passed to t-SNE.\n    \"\"\"\nif standardise:\nif self.is_standardised:\nembeddings_array = np.array(list(self.embeddings.values()))\nelse:\nself.standardise(inplace=True)\nembeddings_array = np.array(list(self.embeddings.values()))\nelse:\nwarnings.warn(\n\"\"\"It is recommended to scale the embeddings\n            before projecting with t-SNE.\n            To do so, set `standardise=True`.\"\"\"\n)\nembeddings_array = np.array(list(self.embeddings.values()))\ntsne = TSNE(n_components=n_components, **kwargs)\ntsne_result = tsne.fit_transform(embeddings_array)\nself._tsne_data = tsne_result\nreturn self._tsne_data\n</code></pre>"},{"location":"python_api/core/#elementembeddings.core.Embedding.citation","title":"<code>citation()</code>","text":"<p>Return a citation for the embedding.</p> Source code in <code>src/elementembeddings/core.py</code> <pre><code>def citation(self) -&gt; List[str]:\n\"\"\"Return a citation for the embedding.\"\"\"\nif self.embedding_name in [\"magpie\", \"magpie_sc\"]:\ncitation = [\n\"@article{ward2016general,\"\n\"title={A general-purpose machine learning framework for \"\n\"predicting properties of inorganic materials},\"\n\"author={Ward, Logan and Agrawal, Ankit and Choudhary, Alok \"\n\"and Wolverton, Christopher},\"\n\"journal={npj Computational Materials},\"\n\"volume={2},\"\n\"number={1},\"\n\"pages={1--7},\"\n\"year={2016},\"\n\"publisher={Nature Publishing Group}}\"\n]\nelif self.embedding_name == \"mat2vec\":\ncitation = [\n\"@article{tshitoyan2019unsupervised,\"\n\"title={Unsupervised word embeddings capture latent knowledge \"\n\"from materials science literature},\"\n\"author={Tshitoyan, Vahe and Dagdelen, John and Weston, Leigh \"\n\"and Dunn, Alexander and Rong, Ziqin and Kononova, Olga \"\n\"and Persson, Kristin A and Ceder, Gerbrand and Jain, Anubhav},\"\n\"journal={Nature},\"\n\"volume={571},\"\n\"number={7763},\"\n\"pages={95--98},\"\n\"year={2019},\"\n\"publisher={Nature Publishing Group} }\"\n]\nelif self.embedding_name == \"matscholar\":\ncitation = [\n\"@article{weston2019named,\"\n\"title={Named entity recognition and normalization applied to \"\n\"large-scale information extraction from the materials \"\n\"science literature},\"\n\"author={Weston, Leigh and Tshitoyan, Vahe and Dagdelen, John and \"\n\"Kononova, Olga and Trewartha, Amalie and Persson, Kristin A and \"\n\"Ceder, Gerbrand and Jain, Anubhav},\"\n\"journal={Journal of chemical information and modeling},\"\n\"volume={59},\"\n\"number={9},\"\n\"pages={3692--3702},\"\n\"year={2019},\"\n\"publisher={ACS Publications} }\"\n]\nelif self.embedding_name == \"megnet16\":\ncitation = [\n\"@article{chen2019graph,\"\n\"title={Graph networks as a universal machine learning framework \"\n\"for molecules and crystals},\"\n\"author={Chen, Chi and Ye, Weike and Zuo, Yunxing and \"\n\"Zheng, Chen and Ong, Shyue Ping},\"\n\"journal={Chemistry of Materials},\"\n\"volume={31},\"\n\"number={9},\"\n\"pages={3564--3572},\"\n\"year={2019},\"\n\"publisher={ACS Publications} }\"\n]\nelif self.embedding_name in [\"oliynyk\", \"oliynyk_sc\"]:\ncitation = [\n\"              @article{oliynyk2016high,\"\n\"title={High-throughput machine-learning-driven synthesis \"\n\"of full-Heusler compounds},\"\n\"author={Oliynyk, Anton O and Antono, Erin and Sparks, Taylor D and \"\n\"Ghadbeigi, Leila and Gaultois, Michael W and \"\n\"Meredig, Bryce and Mar, Arthur},\"\n\"journal={Chemistry of Materials},\"\n\"volume={28},\"\n\"number={20},\"\n\"pages={7324--7331},\"\n\"year={2016},\"\n\"publisher={ACS Publications} }\"\n]\nelif self.embedding_name == \"skipatom\":\ncitation = [\n\"@article{antunes2022distributed,\"\n\"title={Distributed representations of atoms and materials \"\n\"for machine learning},\"\n\"author={Antunes, Luis M and Grau-Crespo, Ricardo and Butler, Keith T},\"\n\"journal={npj Computational Materials},\"\n\"volume={8},\"\n\"number={1},\"\n\"pages={1--9},\"\n\"year={2022},\"\n\"publisher={Nature Publishing Group} }\"\n]\nelif self.embedding_name == \"mod_petti\":\ncitation = [\n\"@article{glawe2016optimal,\"\n\"title={The optimal one dimensional periodic table: \"\n\"a modified Pettifor chemical scale from data mining},\"\n\"author={Glawe, Henning and Sanna, Antonio and Gross, \"\n\"EKU and Marques, Miguel AL},\"\n\"journal={New Journal of Physics},\"\n\"volume={18},\"\n\"number={9},\"\n\"pages={093011},\"\n\"year={2016},\"\n\"publisher={IOP Publishing} }\"\n]\nelse:\ncitation = []\nreturn citation\n</code></pre>"},{"location":"python_api/core/#elementembeddings.core.Embedding.compute_correlation_metric","title":"<code>compute_correlation_metric(ele1, ele2, metric='pearson')</code>","text":"<p>Compute the correlation/similarity metric between two vectors.</p> <p>Allowed metrics: * Pearson * Spearman * Cosine similarity</p> <p>Parameters:</p> Name Type Description Default <code>ele1</code> <code>str</code> <p>element symbol</p> required <code>ele2</code> <code>str</code> <p>element symbol</p> required <code>metric</code> <code>str</code> <p>name of a correlation metric.</p> <code>'pearson'</code> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>correlation/similarity metric</p> Source code in <code>src/elementembeddings/core.py</code> <pre><code>def compute_correlation_metric(\nself, ele1: str, ele2: str, metric: str = \"pearson\"\n) -&gt; float:\n\"\"\"\n    Compute the correlation/similarity metric between two vectors.\n    Allowed metrics:\n    * Pearson\n    * Spearman\n    * Cosine similarity\n    Args:\n        ele1 (str): element symbol\n        ele2 (str): element symbol\n        metric (str): name of a correlation metric.\n        Options are \"spearman\", \"pearson\" and \"cosine_similarity\".\n    Returns:\n        float: correlation/similarity metric\n    \"\"\"\n# Define the allowable metrics\nscipy_corrs = {\"pearson\": pearsonr, \"spearman\": spearmanr}\nif metric == \"pearson\":\nreturn scipy_corrs[metric](\nself.embeddings[ele1], self.embeddings[ele2]\n).statistic\nelif metric == \"spearman\":\nreturn scipy_corrs[metric](\nself.embeddings[ele1], self.embeddings[ele2]\n).correlation\nelif metric == \"cosine_similarity\":\nreturn cosine_similarity(self.embeddings[ele1], self.embeddings[ele2])\n</code></pre>"},{"location":"python_api/core/#elementembeddings.core.Embedding.compute_distance_metric","title":"<code>compute_distance_metric(ele1, ele2, metric='euclidean')</code>","text":"<p>Compute distance metric between two vectors.</p> <p>Allowed metrics:</p> <ul> <li>euclidean</li> <li>manhattan</li> <li>chebyshev</li> <li>wasserstein</li> <li>energy</li> <li>cosine_distance</li> </ul> <p>Parameters:</p> Name Type Description Default <code>ele1</code> <code>str</code> <p>element symbol</p> required <code>ele2</code> <code>str</code> <p>element symbol</p> required <code>metric</code> <code>str</code> <p>name of a distance metric</p> <code>'euclidean'</code> <p>Returns:</p> Name Type Description <code>distance</code> <code>float</code> <p>distance between embedding vectors</p> Source code in <code>src/elementembeddings/core.py</code> <pre><code>def compute_distance_metric(\nself, ele1: str, ele2: str, metric: str = \"euclidean\"\n) -&gt; float:\n\"\"\"\n    Compute distance metric between two vectors.\n    Allowed metrics:\n    * euclidean\n    * manhattan\n    * chebyshev\n    * wasserstein\n    * energy\n    * cosine_distance\n    Args:\n        ele1 (str): element symbol\n        ele2 (str): element symbol\n        metric (str): name of a distance metric\n    Returns:\n        distance (float): distance between embedding vectors\n    \"\"\"\n# Define the allowable metrics\nscikit_metrics = [\"euclidean\", \"manhattan\", \"chebyshev\"]\nscipy_metrics = {\"wasserstein\": wasserstein_distance, \"energy\": energy_distance}\nvalid_metrics = scikit_metrics + list(scipy_metrics.keys()) + [\"cosine\"]\n# Validate if the elements are within the embedding vector\nif not all([self._is_el_in_embedding(ele1), self._is_el_in_embedding(ele2)]):\nif not self._is_el_in_embedding(ele1):\nprint(f\"{ele1} is not an element included within the atomic embeddings\")\nraise ValueError\nelif not self._is_el_in_embedding(ele2):\nprint(f\"{ele2} is not an element included within the atomic embeddings\")\nraise ValueError\n# Compute the distance measure\nif metric in scikit_metrics:\ndistance = DistanceMetric.get_metric(metric)\nreturn distance.pairwise(\nself.embeddings[ele1].reshape(1, -1),\nself.embeddings[ele2].reshape(1, -1),\n)[0][0]\nelif metric in scipy_metrics.keys():\nreturn scipy_metrics[metric](self.embeddings[ele1], self.embeddings[ele2])\nelif metric == \"cosine_distance\":\nreturn cosine_distance(self.embeddings[ele1], self.embeddings[ele2])\nelse:\nprint(\n\"Invalid distance metric.\"\nf\"Use one of the following metrics:{valid_metrics}\"\n)\nraise ValueError\n</code></pre>"},{"location":"python_api/core/#elementembeddings.core.Embedding.correlation_df","title":"<code>correlation_df(metric='pearson')</code>","text":"<p>Return a dataframe with columns [\"ele_1\", \"ele_2\", metric].</p> <p>Allowed metrics:</p> <ul> <li>pearson</li> <li>spearman</li> <li>cosine_similarity</li> </ul> <p>Parameters:</p> Name Type Description Default <code>metric</code> <code>str</code> <p>A distance metric.</p> <code>'pearson'</code> <p>Returns:</p> Name Type Description <code>df</code> <code>pandas.DataFrame</code> <p>A dataframe with columns [\"ele_1\", \"ele_2\", metric].</p> Source code in <code>src/elementembeddings/core.py</code> <pre><code>def correlation_df(self, metric: str = \"pearson\") -&gt; pd.DataFrame:\n\"\"\"\n    Return a dataframe with columns [\"ele_1\", \"ele_2\", metric].\n    Allowed metrics:\n    * pearson\n    * spearman\n    * cosine_similarity\n    Args:\n        metric (str): A distance metric.\n    Returns:\n        df (pandas.DataFrame): A dataframe with columns [\"ele_1\", \"ele_2\", metric].\n    \"\"\"\nele_pairs = self.create_pairs()\ntable = []\nfor ele1, ele2 in ele_pairs:\ndist = self.compute_correlation_metric(ele1, ele2, metric=metric)\ntable.append((ele1, ele2, dist))\nif ele1 != ele2:\ntable.append((ele2, ele1, dist))\ncorr_df = pd.DataFrame(table, columns=[\"ele_1\", \"ele_2\", metric])\nmend_1 = [(Element(ele).mendeleev_no, ele) for ele in corr_df[\"ele_1\"]]\nmend_2 = [(Element(ele).mendeleev_no, ele) for ele in corr_df[\"ele_2\"]]\nZ_1 = [(pt[ele][\"number\"], ele) for ele in corr_df[\"ele_1\"]]\nZ_2 = [(pt[ele][\"number\"], ele) for ele in corr_df[\"ele_2\"]]\ncorr_df[\"mend_1\"] = mend_1\ncorr_df[\"mend_2\"] = mend_2\ncorr_df[\"Z_1\"] = Z_1\ncorr_df[\"Z_2\"] = Z_2\ncorr_df = corr_df[[\"ele_1\", \"ele_2\", \"mend_1\", \"mend_2\", \"Z_1\", \"Z_2\", metric]]\nreturn corr_df\n</code></pre>"},{"location":"python_api/core/#elementembeddings.core.Embedding.correlation_pivot_table","title":"<code>correlation_pivot_table(metric='pearson', sortby='mendeleev')</code>","text":"<p>Return a pandas.DataFrame style pivot.</p> <p>The index and column being either the mendeleev number or atomic number of the element pairs and the values being a user-specified distance metric.</p> <p>Parameters:</p> Name Type Description Default <code>metric</code> <code>str</code> <p>A distance metric.</p> <code>'pearson'</code> <code>sortby</code> <code>str</code> <p>Sort the pivot table by either \"mendeleev\" or \"atomic_number\".</p> <code>'mendeleev'</code> <p>Returns:</p> Name Type Description <code>distance_pivot</code> <code>pandas.DataFrame</code> <p>A pandas DataFrame pivot table.</p> Source code in <code>src/elementembeddings/core.py</code> <pre><code>def correlation_pivot_table(\nself, metric: str = \"pearson\", sortby: str = \"mendeleev\"\n) -&gt; pd.DataFrame:\n\"\"\"\n    Return a pandas.DataFrame style pivot.\n    The index and column being either the mendeleev number or atomic number\n    of the element pairs and the values being a user-specified distance metric.\n    Args:\n        metric (str): A distance metric.\n        sortby (str): Sort the pivot table by either \"mendeleev\" or \"atomic_number\".\n    Returns:\n        distance_pivot (pandas.DataFrame): A pandas DataFrame pivot table.\n    \"\"\"\ncorr_df = self.correlation_df(metric=metric)\nif sortby == \"mendeleev\":\ncorrelation_pivot = corr_df.pivot_table(\nvalues=metric, index=\"mend_1\", columns=\"mend_2\"\n)\nreturn correlation_pivot\nelif sortby == \"atomic_number\":\ncorrelation_pivot = corr_df.pivot_table(\nvalues=metric, index=\"Z_1\", columns=\"Z_2\"\n)\nreturn correlation_pivot\n</code></pre>"},{"location":"python_api/core/#elementembeddings.core.Embedding.create_pairs","title":"<code>create_pairs()</code>","text":"<p>Create all possible pairs of elements.</p> Source code in <code>src/elementembeddings/core.py</code> <pre><code>def create_pairs(self):\n\"\"\"Create all possible pairs of elements.\"\"\"\nele_list = self.element_list\nele_pairs = combinations_with_replacement(ele_list, 2)\nreturn ele_pairs\n</code></pre>"},{"location":"python_api/core/#elementembeddings.core.Embedding.distance_df","title":"<code>distance_df(metric='euclidean')</code>","text":"<p>Return a dataframe with columns [\"ele_1\", \"ele_2\", metric].</p> <p>Allowed metrics:</p> <ul> <li>euclidean</li> <li>manhattan</li> <li>chebyshev</li> <li>wasserstein</li> <li>energy</li> </ul> <p>Parameters:</p> Name Type Description Default <code>metric</code> <code>str</code> <p>A distance metric.</p> <code>'euclidean'</code> <p>Returns:</p> Name Type Description <code>df</code> <code>pandas.DataFrame</code> <p>A dataframe with columns [\"ele_1\", \"ele_2\", metric].</p> Source code in <code>src/elementembeddings/core.py</code> <pre><code>def distance_df(self, metric: str = \"euclidean\") -&gt; pd.DataFrame:\n\"\"\"\n    Return a dataframe with columns [\"ele_1\", \"ele_2\", metric].\n    Allowed metrics:\n    * euclidean\n    * manhattan\n    * chebyshev\n    * wasserstein\n    * energy\n    Args:\n        metric (str): A distance metric.\n    Returns:\n        df (pandas.DataFrame): A dataframe with columns [\"ele_1\", \"ele_2\", metric].\n    \"\"\"\nele_pairs = self.create_pairs()\ntable = []\nfor ele1, ele2 in ele_pairs:\ndist = self.compute_distance_metric(ele1, ele2, metric=metric)\ntable.append((ele1, ele2, dist))\nif ele1 != ele2:\ntable.append((ele2, ele1, dist))\ncorr_df = pd.DataFrame(table, columns=[\"ele_1\", \"ele_2\", metric])\nmend_1 = [(Element(ele).mendeleev_no, ele) for ele in corr_df[\"ele_1\"]]\nmend_2 = [(Element(ele).mendeleev_no, ele) for ele in corr_df[\"ele_2\"]]\nZ_1 = [(pt[ele][\"number\"], ele) for ele in corr_df[\"ele_1\"]]\nZ_2 = [(pt[ele][\"number\"], ele) for ele in corr_df[\"ele_2\"]]\ncorr_df[\"mend_1\"] = mend_1\ncorr_df[\"mend_2\"] = mend_2\ncorr_df[\"Z_1\"] = Z_1\ncorr_df[\"Z_2\"] = Z_2\ncorr_df = corr_df[[\"ele_1\", \"ele_2\", \"mend_1\", \"mend_2\", \"Z_1\", \"Z_2\", metric]]\nreturn corr_df\n</code></pre>"},{"location":"python_api/core/#elementembeddings.core.Embedding.distance_pivot_table","title":"<code>distance_pivot_table(metric='euclidean', sortby='mendeleev')</code>","text":"<p>Return a pandas.DataFrame style pivot.</p> <p>The index and column being either the mendeleev number or atomic number of the element pairs and the values being a user-specified distance metric.</p> <p>Parameters:</p> Name Type Description Default <code>metric</code> <code>str</code> <p>A distance metric.</p> <code>'euclidean'</code> <code>sortby</code> <code>str</code> <p>Sort the pivot table by either \"mendeleev\" or \"atomic_number\".</p> <code>'mendeleev'</code> <p>Returns:</p> Name Type Description <code>distance_pivot</code> <code>pandas.DataFrame</code> <p>A pandas DataFrame pivot table.</p> Source code in <code>src/elementembeddings/core.py</code> <pre><code>def distance_pivot_table(\nself, metric: str = \"euclidean\", sortby: str = \"mendeleev\"\n) -&gt; pd.DataFrame:\n\"\"\"\n    Return a pandas.DataFrame style pivot.\n    The index and column being either the mendeleev number or atomic number\n    of the element pairs and the values being a user-specified distance metric.\n    Args:\n        metric (str): A distance metric.\n        sortby (str): Sort the pivot table by either \"mendeleev\" or \"atomic_number\".\n    Returns:\n        distance_pivot (pandas.DataFrame): A pandas DataFrame pivot table.\n    \"\"\"\ncorr_df = self.distance_df(metric=metric)\nif sortby == \"mendeleev\":\ndistance_pivot = corr_df.pivot_table(\nvalues=metric, index=\"mend_1\", columns=\"mend_2\"\n)\nreturn distance_pivot\nelif sortby == \"atomic_number\":\ndistance_pivot = corr_df.pivot_table(\nvalues=metric, index=\"Z_1\", columns=\"Z_2\"\n)\nreturn distance_pivot\n</code></pre>"},{"location":"python_api/core/#elementembeddings.core.Embedding.from_csv","title":"<code>from_csv(embedding_csv, embedding_name=None)</code>  <code>staticmethod</code>","text":"<p>Create an instance of the Embedding class from a csv file.</p> <p>The first column of the csv file must contain the elements and be named element.</p> <p>Parameters:</p> Name Type Description Default <code>embedding_csv</code> <code>str</code> <p>Filepath of the csv file</p> required <code>embedding_name</code> <code>str</code> <p>The name of the elemental representation</p> <code>None</code> Source code in <code>src/elementembeddings/core.py</code> <pre><code>@staticmethod\ndef from_csv(embedding_csv, embedding_name: Optional[str] = None):\n\"\"\"\n    Create an instance of the Embedding class from a csv file.\n    The first column of the csv file must contain the elements and be named element.\n    Args:\n        embedding_csv (str): Filepath of the csv file\n        embedding_name (str): The name of the elemental representation\n    \"\"\"\n# Need to add validation handling for csv files\ndf = pd.read_csv(embedding_csv)\nelements = list(df[\"element\"])\ndf.drop([\"element\"], axis=1, inplace=True)\nfeature_labels = list(df.columns)\nembeds_array = df.to_numpy()\nembedding_data = {\nelements[i]: embeds_array[i] for i in range(len(embeds_array))\n}\nreturn Embedding(embedding_data, embedding_name, feature_labels)\n</code></pre>"},{"location":"python_api/core/#elementembeddings.core.Embedding.from_json","title":"<code>from_json(embedding_json, embedding_name=None)</code>  <code>staticmethod</code>","text":"<p>Create an instance of the Embedding class from a json file.</p> <p>Parameters:</p> Name Type Description Default <code>embedding_json</code> <code>str</code> <p>Filepath of the json file</p> required <code>embedding_name</code> <code>str</code> <p>The name of the elemental representation</p> <code>None</code> Source code in <code>src/elementembeddings/core.py</code> <pre><code>@staticmethod\ndef from_json(embedding_json, embedding_name: Optional[str] = None):\n\"\"\"\n    Create an instance of the Embedding class from a json file.\n    Args:\n        embedding_json (str): Filepath of the json file\n        embedding_name (str): The name of the elemental representation\n    \"\"\"\n# Need to add validation handling for JSONs in different formats\nwith open(embedding_json) as f:\nembedding_data = json.load(f)\nreturn Embedding(embedding_data, embedding_name)\n</code></pre>"},{"location":"python_api/core/#elementembeddings.core.Embedding.load_data","title":"<code>load_data(embedding_name=None)</code>  <code>staticmethod</code>","text":"<p>Create an instance of the <code>Embedding</code> class from a default embedding file.</p> <p>The default embeddings are in the table below:</p> Name str_name Magpie magpie Magpie (scaled) magpie_sc Mat2Vec mat2vec Matscholar matscholar Megnet (16 dimensions) megnet16 Modified pettifor scale mod_petti Oliynyk oliynyk Oliynyk (scaled) oliynyk_sc Random (200 dimensions) random_200 SkipAtom skipatom Atomic Number atomic <p>Parameters:</p> Name Type Description Default <code>embedding_name</code> <code>str</code> <p>The str_name of an embedding file.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Embedding</code> <p>class:<code>Embedding</code> instance.</p> Source code in <code>src/elementembeddings/core.py</code> <pre><code>@staticmethod\ndef load_data(embedding_name: Optional[str] = None):\n\"\"\"\n    Create an instance of the `Embedding` class from a default embedding file.\n    The default embeddings are in the table below:\n    | **Name**                | **str_name** |\n    |-------------------------|--------------|\n    | Magpie                  | magpie       |\n    | Magpie (scaled)         | magpie_sc    |\n    | Mat2Vec                 | mat2vec      |\n    | Matscholar              | matscholar   |\n    | Megnet (16 dimensions)  | megnet16     |\n    | Modified pettifor scale | mod_petti    |\n    | Oliynyk                 | oliynyk      |\n    | Oliynyk (scaled)        | oliynyk_sc   |\n    | Random (200 dimensions) | random_200   |\n    | SkipAtom                | skipatom     |\n    | Atomic Number           | atomic       |\n    Args:\n        embedding_name (str): The str_name of an embedding file.\n    Returns:\n        Embedding :class:`Embedding` instance.\n    \"\"\"\n_cbfv_files = {\n\"magpie\": \"magpie.csv\",\n\"magpie_sc\": \"magpie_sc.json\",\n\"mat2vec\": \"mat2vec.csv\",\n\"matscholar\": \"matscholar-embedding.json\",\n\"megnet16\": \"megnet16.json\",\n\"mod_petti\": \"mod_petti.json\",\n\"oliynyk\": \"oliynyk.csv\",\n\"oliynyk_sc\": \"oliynyk_sc.json\",\n\"random_200\": \"random_200_new.csv\",\n\"skipatom\": \"skipatom_20201009_induced.csv\",\n\"atomic\": \"atomic.json\",\n}\nif _cbfv_files[embedding_name].endswith(\".csv\"):\nreturn Embedding.from_csv(\npath.join(\ndata_directory,\n\"element_representations\",\n_cbfv_files[embedding_name],\n),\nembedding_name,\n)\nelif \"megnet\" in _cbfv_files[embedding_name]:\nreturn Embedding.from_json(\npath.join(\ndata_directory,\n\"element_representations\",\n_cbfv_files[embedding_name],\n),\nembedding_name,\n).remove_elements([\"Null\"])\nelif _cbfv_files[embedding_name].endswith(\".json\"):\nreturn Embedding.from_json(\npath.join(\ndata_directory,\n\"element_representations\",\n_cbfv_files[embedding_name],\n),\nembedding_name,\n)\n</code></pre>"},{"location":"python_api/core/#elementembeddings.core.Embedding.remove_elements","title":"<code>remove_elements(elements, inplace=False)</code>","text":"<p>Remove elements from the Embedding instance.</p> <p>Parameters:</p> Name Type Description Default <code>elements</code> <code>str,list(str</code> <p>An element symbol or a list of element symbols</p> required <code>inplace</code> <code>bool</code> <p>If True, elements are removed from the Embedding instance.</p> <code>False</code> Source code in <code>src/elementembeddings/core.py</code> <pre><code>def remove_elements(self, elements: Union[str, List[str]], inplace: bool = False):\n# TO-DO allow removal by atomic numbers\n\"\"\"\n    Remove elements from the Embedding instance.\n    Args:\n        elements (str,list(str)): An element symbol or a list of element symbols\n        inplace (bool): If True, elements are removed from the Embedding instance.\n        If false, the original embedding instance is unchanged\n        and a new embedding instance with the elements removed is created.\n    \"\"\"\nif inplace:\nif isinstance(elements, str):\ndel self.embeddings[elements]\nelif isinstance(elements, list):\nfor el in elements:\ndel self.embeddings[el]\nreturn None\nelse:\nembeddings_copy = self.embeddings.copy()\nif isinstance(elements, str):\ndel embeddings_copy[elements]\nelif isinstance(elements, list):\nfor el in elements:\ndel embeddings_copy[el]\nreturn Embedding(embeddings_copy, self.embedding_name)\n</code></pre>"},{"location":"python_api/core/#elementembeddings.core.Embedding.standardise","title":"<code>standardise(inplace=False)</code>","text":"<p>Standardise the embeddings.</p> <p>Mean is 0 and standard deviation is 1.</p> Source code in <code>src/elementembeddings/core.py</code> <pre><code>def standardise(self, inplace: bool = False):\n\"\"\"Standardise the embeddings.\n    Mean is 0 and standard deviation is 1.\n    \"\"\"\nif self._is_standardised():\nwarnings.warn(\n\"Embedding is already standardised. \"\n\"Returning None and not changing the embedding.\"\n)\nreturn None\nelse:\nembeddings_copy = self.embeddings.copy()\nembeddings_array = np.array(list(embeddings_copy.values()))\nembeddings_array = StandardScaler().fit_transform(embeddings_array)\nfor el, emb in zip(embeddings_copy.keys(), embeddings_array):\nembeddings_copy[el] = emb\nif inplace:\nself.embeddings = embeddings_copy\nself.is_standardised = True\nreturn None\nelse:\nreturn Embedding(embeddings_copy, self.embedding_name)\n</code></pre>"},{"location":"python_api/core/#elementembeddings.core.Embedding.to","title":"<code>to(fmt='', filename='')</code>","text":"<p>Output the embedding to a file.</p> <p>Parameters:</p> Name Type Description Default <code>fmt</code> <code>str</code> <p>The file format to output the embedding to.</p> <code>''</code> <code>filename</code> <code>str</code> <p>The name of the file to be outputted</p> <code>''</code> <p>Returns:</p> Type Description <p>(str) if filename not specified, otherwise None.</p> Source code in <code>src/elementembeddings/core.py</code> <pre><code>def to(self, fmt: str = \"\", filename: Optional[str] = \"\"):\n\"\"\"\n    Output the embedding to a file.\n    Args:\n        fmt (str): The file format to output the embedding to.\n        Options include \"json\" and \"csv\".\n        filename (str): The name of the file to be outputted\n    Returns:\n        (str) if filename not specified, otherwise None.\n    \"\"\"\nfmt = fmt.lower()\nif fmt == \"json\" or fnmatch.fnmatch(filename, \"*.json\"):\nj = json.dumps(self.embeddings, cls=NumpyEncoder)\nif filename:\nif not filename.endswith(\".json\"):\nfilename = filename + \".json\"\nwith open(filename, \"w\") as file:\nfile.write(j)\nelse:\nreturn j\nelif fmt == \"csv\" or fnmatch.fnmatch(filename, \"*.csv\"):\nif filename:\nif not filename.endswith(\".csv\"):\nfilename = filename + \".csv\"\nself.as_dataframe().to_csv(filename, index_label=\"element\")\nelse:\nreturn self.as_dataframe().to_csv(index_label=\"element\")\nelse:\nraise ValueError(f\"{str(fmt)} is an invalid file format\")\n</code></pre>"},{"location":"python_api/plotter/","title":"Plotter module","text":"<p>Provides the plotting functions for visualising Embeddings.</p>"},{"location":"python_api/plotter/#elementembeddings.plotter.dimension_plotter","title":"<code>dimension_plotter(embedding, ax=None, n_components=2, reducer='umap', adjusttext=True, reducer_params=None, scatter_params=None)</code>","text":"<p>Plot the reduced dimensions of the embeddings.</p> <p>Parameters:</p> Name Type Description Default <code>embedding</code> <code>Embedding</code> <p>The embedding to be plotted.</p> required <code>ax</code> <code>plt.axes</code> <p>The axes to plot on, by default None</p> <code>None</code> <code>n_components</code> <code>int</code> <p>The number of components to reduce to, by default 2</p> <code>2</code> <code>reducer</code> <code>str</code> <p>The dimensionality reduction algorithm to use, by default \"umap\"</p> <code>'umap'</code> <code>adjust_text</code> <code>bool</code> <p>Whether to avoid overlap of the text labels, by default True</p> required <code>reducer_params</code> <code>dict</code> <p>Additional keyword arguments to pass to</p> <code>None</code> <code>scatter_params</code> <code>dict</code> <p>Additional keyword arguments to pass to</p> <code>None</code> Source code in <code>src/elementembeddings/plotter.py</code> <pre><code>def dimension_plotter(\nembedding: Embedding,\nax: Optional[plt.axes] = None,\nn_components: int = 2,\nreducer: str = \"umap\",\nadjusttext: bool = True,\nreducer_params: Optional[dict] = None,\nscatter_params: Optional[dict] = None,\n):\n\"\"\"Plot the reduced dimensions of the embeddings.\n    Args:\n        embedding (Embedding): The embedding to be plotted.\n        ax (plt.axes, optional): The axes to plot on, by default None\n        n_components (int): The number of components to reduce to, by default 2\n        reducer (str): The dimensionality reduction algorithm to use, by default \"umap\"\n        adjust_text (bool): Whether to avoid overlap of the text labels, by default True\n        reducer_params (dict, optional): Additional keyword arguments to pass to\n        the reducer, by default None\n        scatter_params (dict, optional): Additional keyword arguments to pass to\n        the scatterplot, by default None\n    \"\"\"\nif reducer_params is None:\nreducer_params = {}\nif reducer == \"umap\":\nif (\nembedding._umap_data is not None\nand embedding._umap_data.shape[1] == n_components\n):\nreduced = embedding._umap_data\nelse:\nreduced = embedding.calculate_UMAP(\nn_components=n_components, **reducer_params\n)\nelif reducer == \"tsne\":\nif (\nembedding._tsne_data is not None\nand embedding._tsne_data.shape[1] == n_components\n):\nreduced = embedding._tsne_data\nelse:\nreduced = embedding.calculate_tSNE(\nn_components=n_components, **reducer_params\n)\nelif reducer == \"pca\":\nif (\nembedding._pca_data is not None\nand embedding._pca_data.shape[1] == n_components\n):\nreduced = embedding._pca_data\nelse:\nreduced = embedding.calculate_PC(\nn_components=n_components, **reducer_params\n)\nelse:\nraise ValueError(\"Unrecognised reducer.\")\nif reduced.shape[1] == 2:\ndf = pd.DataFrame(\n{\n\"x\": reduced[:, 0],\n\"y\": reduced[:, 1],\n\"element\": np.array(embedding.element_list),\n\"Group\": list(embedding.element_groups_dict.values()),\n}\n)\nif not ax:\nfig, ax = plt.subplots()\nif scatter_params is None:\nscatter_params = {}\nsns.scatterplot(data=df, x=\"x\", y=\"y\", hue=\"Group\", ax=ax, **scatter_params)\nax.set_xlabel(\"Dimension 1\")\nax.set_ylabel(\"Dimension 2\")\ntexts = [\nax.text(df[\"x\"][i], df[\"y\"][i], df[\"element\"][i], fontsize=12)\nfor i in range(len(df))\n]\nif adjusttext:\nadjust_text(\ntexts, arrowprops=dict(arrowstyle=\"-\", color=\"gray\", lw=0.5), ax=ax\n)\nelif reduced.shape[1] == 3:\ndf = pd.DataFrame(\n{\n\"x\": reduced[:, 0],\n\"y\": reduced[:, 1],\n\"z\": reduced[:, 2],\n\"element\": np.array(embedding.element_list),\n\"group\": list(embedding.element_groups_dict.values()),\n}\n)\nif not ax:\nfig = plt.figure()  # noqa: F841\nax = plt.axes(projection=\"3d\")\nax.scatter3D(\ndf[\"x\"],\ndf[\"y\"],\ndf[\"z\"],\n)\nax.set_xlabel(\"Dimension 1\")\nax.set_ylabel(\"Dimension 2\")\nax.set_zlabel(\"Dimension 3\")\nfor i in range(len(df)):\nax.text(df[\"x\"][i], df[\"y\"][i], df[\"z\"][i], df[\"element\"][i], fontsize=12)\nelse:\nraise ValueError(\"Unrecognised number of dimensions.\")\nax.set_title(embedding.embedding_name, fontdict={\"fontweight\": \"bold\"})\nreturn ax\n</code></pre>"},{"location":"python_api/plotter/#elementembeddings.plotter.heatmap_plotter","title":"<code>heatmap_plotter(embedding, metric, cmap='Blues', sortaxisby='mendeleev', ax=None, show_axislabels=True, **kwargs)</code>","text":"<p>Plot multiple heatmaps of the embeddings.</p> <p>Parameters:</p> Name Type Description Default <code>embedding</code> <code>Embedding</code> <p>The embeddings to be plotted.</p> required <code>metric</code> <code>str</code> <p>The distance metric / similarity measure to be plotted.</p> required <code>cmap</code> <code>str</code> <p>The colourmap for the heatmap.</p> <code>'Blues'</code> <code>sortaxisby</code> <code>str</code> <p>The attribute to sort the axis by,</p> <code>'mendeleev'</code> <code>ax</code> <code>plt.axes</code> <p>The axes to plot on, by default None</p> <code>None</code> <code>show_axislabels</code> <code>bool</code> <p>Whether to show the axis, by default True</p> <code>True</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to seaborn.heatmap</p> <code>{}</code> Source code in <code>src/elementembeddings/plotter.py</code> <pre><code>def heatmap_plotter(\nembedding: Embedding,\nmetric: str,\ncmap: str = \"Blues\",\nsortaxisby: str = \"mendeleev\",\nax: Optional[plt.axes] = None,\nshow_axislabels: bool = True,\n**kwargs,\n):\n\"\"\"\n    Plot multiple heatmaps of the embeddings.\n    Args:\n        embedding (Embedding): The embeddings to be plotted.\n        metric (str): The distance metric / similarity measure to be plotted.\n        cmap (str): The colourmap for the heatmap.\n        sortaxisby (str, optional): The attribute to sort the axis by,\n        by default \"mendeleev_number\".\n        Options are \"mendeleev_number\", \"atomic_number\"\n        ax (plt.axes, optional): The axes to plot on, by default None\n        show_axislabels (bool, optional): Whether to show the axis, by default True\n        **kwargs: Additional keyword arguments to pass to seaborn.heatmap\n    \"\"\"\nif not ax:\nfig, ax = plt.subplots()\ncorrelation_metrics = [\"spearman\", \"pearson\", \"cosine_similarity\"]\ndistance_metrics = [\n\"euclidean\",\n\"manhattan\",\n\"cosine_distance\",\n\"chebyshev\",\n\"wasserstein\",\n\"energy\",\n]\nif metric in correlation_metrics:\np = embedding.correlation_pivot_table(metric=metric, sortby=sortaxisby)\nelif metric in distance_metrics:\np = embedding.distance_pivot_table(metric=metric, sortby=sortaxisby)\nxlabels = [i[1] for i in p.index]\nylabels = [i[1] for i in p.columns]\nsns.heatmap(\np,\ncmap=cmap,\nsquare=\"True\",\nlinecolor=\"k\",\nax=ax,\ncbar_kws={\n\"shrink\": 0.5,\n},\nxticklabels=True,\nyticklabels=True,\n**kwargs,\n)\nax.set_title(\nembedding.embedding_name,\nfontdict={\n# \"fontsize\": 30,\n\"fontweight\": \"bold\"\n},\n)\nif not show_axislabels:\nax.set_xticklabels([])\nax.set_yticklabels([])\nax.set_xticks([])\nax.set_yticks([])\nelse:\nax.set_xticklabels(\nxlabels,\n)\nax.set_yticklabels(ylabels)\nax.set_xlabel(\"\")\nax.set_ylabel(\"\")\nreturn ax\n</code></pre>"},{"location":"python_api/python_api/","title":"ElementEmbeddings Python package","text":"<p>The core module of the <code>ElementEmbeddings</code> contains the <code>Embedding</code> class which is used to store and manipulate elemental representation data. This part of the project documentation provides the python API for the <code>ElementEmbeddings</code> package.</p> <p>Core module</p> <p>Composition module</p> <p>Plotter module</p>"}]}